{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs\n",
    "Playing with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If using one or multiple GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom RNN cells\n",
    "I'll first create my own basic RNN cells to test my understanding of how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RNN cell, naive input\n",
    "This is a simple RNN cell that simply applies linear transformations to the state and input at time t, adds them together, and applies the `tanh` non-linearity (as depicted in [Chris Olah's blog post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)):\n",
    "\n",
    "![image](./rnn/SimpleRNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_cell:\n",
    "    def __init__(self, x, num_hidden, num_output, activation='tanh'):\n",
    "        # Get input shape\n",
    "        input_shape = x.get_shape().as_list()\n",
    "        batch_size = input_shape[0]\n",
    "        input_size = input_shape[1] # assume flattened\n",
    "        \n",
    "        # Set weight matrices\n",
    "        self.W_xh = tf.Variable(tf.truncated_normal([input_size, num_hidden]), name='W_xh')\n",
    "        self.W_hh = tf.Variable(tf.truncated_normal([num_hidden, num_hidden]), name='W_hh')\n",
    "        self.W_hy = tf.Variable(tf.truncated_normal([num_hidden, num_output]), name='W_hy')\n",
    "        \n",
    "        # Define hidden state and input\n",
    "        self.state = tf.placeholder(tf.float32, shape=[batch_size, num_hidden], name='hidden_state')\n",
    "        self.zero_state = np.zeros([batch_size, num_hidden])\n",
    "        self.current_state = self.zero_state\n",
    "        \n",
    "        # Define computations\n",
    "        self.x = x\n",
    "        self.h1 = tf.matmul(self.x, self.W_xh) # input transform\n",
    "        self.h2 = tf.matmul(self.state, self.W_hh) # hidden transform\n",
    "        self.s = tf.tanh(tf.add(self.h1, self.h2)) # update state\n",
    "        self.y = tf.matmul(self.s, self.W_hy)\n",
    "        \n",
    "        # tf session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def step(self, x):\n",
    "        # Compute output and new state\n",
    "        y, new_state = self.sess.run([self.y, self.s], \n",
    "                                     feed_dict={self.state: self.current_state, self.x: x})\n",
    "        # Update current state\n",
    "        self.current_state = new_state\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def out(self, X):\n",
    "        self.current_state = self.zero_state\n",
    "        y = []\n",
    "        for x_t in X:\n",
    "            y.append(self.step(x_t))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 2\n",
    "input_size = 4\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, input_size])\n",
    "num_hidden = 3\n",
    "num_output = 1\n",
    "rnn = RNN_cell(x, num_hidden, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [-0.72981167]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.5832566  -0.2486003   0.43648246]]\n",
      "\n",
      "[[ 0.        ]\n",
      " [ 0.18836218]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.51001525  0.59857416  0.27309674]]\n",
      "\n",
      "[[ 0.        ]\n",
      " [ 0.30364376]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [-0.24466427  0.20748833 -0.41599485]]\n",
      "\n",
      "[[ 0.        ]\n",
      " [-1.24082625]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.59718233 -0.70386559  0.4279916 ]]\n",
      "\n",
      "[[ 0.        ]\n",
      " [ 0.13348949]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.77958661  0.69025028  0.59718585]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    x = [[0, 0, 0, 0], [1, 1, 1, 1]]\n",
    "    y = rnn.step(x)\n",
    "    print(y)\n",
    "    print(rnn.current_state)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [-0.72981167]]\n",
      "[[ 0.        ]\n",
      " [ 0.18836218]]\n",
      "[[ 0.        ]\n",
      " [ 0.30364376]]\n",
      "[[ 0.        ]\n",
      " [-1.24082625]]\n",
      "[[ 0.        ]\n",
      " [ 0.13348949]]\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.77958661  0.69025028  0.59718585]]\n"
     ]
    }
   ],
   "source": [
    "# Time major axis\n",
    "X = np.ones([5, batch_size, input_size])\n",
    "X[:, 0, :] = 0\n",
    "y = rnn.out(X)\n",
    "[print(y_t) for y_t in y]\n",
    "print(rnn.current_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RNN cell, sequential input\n",
    "Rather than passing inputs from individual time steps with shape `[t, batch_size, ...]` through the RNN multiple times, we can instead pass input that has sequences stacked along the batch dimension, i.e. with shape `[t * batch_size, ...]` of the form $\\{x^1_1, ..., x^1_n, x^2_1, ..., x^2_n, x^3_1, ...\\}$ and then let the RNN cell take care of reshaping into time sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]]]\n",
      "\n",
      "B[0]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "B[1]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "B[2]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Sample parameters\n",
    "batch_size = 3\n",
    "trace_length = 2\n",
    "\n",
    "# shape = [batch_size * trace_length, ...] in form shown above\n",
    "A = np.ones([batch_size * trace_length, 3, 3])\n",
    "for i in range(2):\n",
    "    A[i::2, ...] = i\n",
    "print(\"A\")\n",
    "print(A) # each batch contains a 3x3 matrix of zeros followed by 3x3 matrix of ones\n",
    "print()\n",
    "\n",
    "# reshape to [batch_size, trace_]\n",
    "B = np.reshape(A, [3, 2, 3, 3])\n",
    "for i in range(B.shape[0]):\n",
    "    print(\"B[%d]\" % i)\n",
    "    print(B[i, 0]) # should print 3x3 matrix of zeros\n",
    "    print(B[i, 1]) # should print 3x3 matrix of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_cell:\n",
    "    def __init__(self, x, num_hidden, num_output, activation='tanh'): \n",
    "        # Get input shape\n",
    "        input_shape = x.get_shape().as_list()\n",
    "        batch_size = input_shape[0]\n",
    "        trace_length = input_shape[1]\n",
    "        input_size = input_shape[2] # assume flattened\n",
    "        self.x = tf.placeholder(tf.float32, shape=[batch_size, input_size]) # input placeholder (or input layer)\n",
    "        \n",
    "        # Set weight matrices\n",
    "        self.W_xh = tf.Variable(tf.truncated_normal([input_size, num_hidden]), name='W_xh')\n",
    "        self.W_hh = tf.Variable(tf.truncated_normal([num_hidden, num_hidden]), name='W_hh')\n",
    "        self.W_hy = tf.Variable(tf.truncated_normal([num_hidden, num_output]), name='W_hy')\n",
    "        \n",
    "        # Define hidden state and input\n",
    "        self.state = tf.placeholder(tf.float32, shape=[batch_size, num_hidden], name='hidden_state')\n",
    "        self.zero_state = np.zeros([batch_size, num_hidden])\n",
    "        self.current_state = self.zero_state\n",
    "        \n",
    "        # Set up main computational graph\n",
    "        self.h1 = tf.matmul(self.x, self.W_xh) # input transform\n",
    "        self.h2 = tf.matmul(self.state, self.W_hh) # hidden transform\n",
    "        self.s = tf.tanh(tf.add(self.h1, self.h2)) # update state\n",
    "        self.y = tf.matmul(self.s, self.W_hy) # output at time t\n",
    "        \n",
    "        # tf session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def step(self, x):\n",
    "        # shape(x) = [batch_size, input_size] at time t\n",
    "        # Compute output and new state\n",
    "        y, new_state = self.sess.run([self.y, self.s], \n",
    "                                     feed_dict={self.state: self.current_state, self.x: x})\n",
    "        # Update current state\n",
    "        self.current_state = new_state\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def out(self, X):\n",
    "        # Reset state to zero state\n",
    "        self.current_state = self.zero_state\n",
    "        \n",
    "        # Pass batch input x_t for each time step t\n",
    "        y = []\n",
    "        for i in range(X.shape[1]):\n",
    "            y.append(self.step(X[:, i, ...]))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.11198759],\n",
      "       [ 0.88573521]], dtype=float32), array([[ 1.48039114],\n",
      "       [ 1.31830537]], dtype=float32), array([[ 1.42966747],\n",
      "       [ 1.2085216 ]], dtype=float32), array([[ 1.28310418],\n",
      "       [ 1.6828239 ]], dtype=float32), array([[ 1.30481863],\n",
      "       [ 1.18696034]], dtype=float32)]\n",
      "[[ 0.29764178  0.47977298  0.99106669]\n",
      " [ 0.02432045  0.49872658  0.99757266]]\n"
     ]
    }
   ],
   "source": [
    "# Set up RNN cell\n",
    "tf.reset_default_graph()\n",
    "batch_size = 2\n",
    "trace_length = 5\n",
    "input_size = 4\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, trace_length, input_size])\n",
    "num_hidden = 3\n",
    "num_output = 1\n",
    "rnn = RNN_cell(x, num_hidden, num_output)\n",
    "\n",
    "# Same test run\n",
    "x = np.random.random([batch_size, trace_length, input_size]) \n",
    "y = rnn.out(x)\n",
    "print(y)\n",
    "print(rnn.current_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM cell\n",
    "Now let's try to build an LSTM cell, following this graphical depiction from [Chris Olah's blog post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/):\n",
    "\n",
    "![image](./rnn/LSTM.png)\n",
    "\n",
    "A small note: we will be concatenating the input and hidden states rather than simply adding them to be consistent with the notation in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_cell:\n",
    "    def __init__(self, x, num_hidden, activation='tanh'): \n",
    "        # Get input shape\n",
    "        input_shape = x.get_shape().as_list()\n",
    "        batch_size = input_shape[0]\n",
    "        trace_length = input_shape[1]\n",
    "        input_size = input_shape[2] # assume flattened\n",
    "        self.x = tf.placeholder(tf.float32, \n",
    "                                shape=[batch_size, input_size],\n",
    "                                name='x_t') # input placeholder (or input layer)\n",
    "        \n",
    "        # Zero state\n",
    "        self.zero_state = np.zeros([batch_size, num_hidden])\n",
    "\n",
    "        # Cell state\n",
    "        self.cell_state = tf.placeholder(tf.float32,\n",
    "                                         shape=[batch_size, num_hidden],\n",
    "                                         name='cell_state')\n",
    "        self.current_cell_state = self.zero_state\n",
    "\n",
    "        # Hidden state\n",
    "        self.hidden_state = tf.placeholder(tf.float32, \n",
    "                                           shape=[batch_size, num_hidden], \n",
    "                                           name='hidden_state')\n",
    "        self.current_hidden_state = self.zero_state\n",
    "\n",
    "        # Forget gate\n",
    "        with tf.name_scope(\"forget_gate\"):\n",
    "            self.W_f = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_f')\n",
    "            self.b_f = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_f\")\n",
    "            self.f_t = tf.matmul(tf.concat([self.hidden_state, self.x], 1), self.W_f) + self.b_f\n",
    "            self.f_t = tf.sigmoid(self.f_t, name='f_t')\n",
    "        \n",
    "        # Input gate\n",
    "        with tf.name_scope(\"input_gate\"):\n",
    "            self.W_i = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_i')\n",
    "            self.b_i = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_i\")\n",
    "            self.i_t = tf.matmul(tf.concat([self.hidden_state, self.x], 1), self.W_i) + self.b_i\n",
    "            self.i_t = tf.sigmoid(self.i_t, name='i_t')\n",
    "        \n",
    "        \n",
    "        # New cell state candidate values\n",
    "        with tf.name_scope(\"candidate_values\"):\n",
    "            self.W_c = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_c')\n",
    "            self.b_c = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_c\")\n",
    "            self.c_t_ = tf.matmul(tf.concat([self.hidden_state, self.x], 1), self.W_c) + self.b_c\n",
    "            self.c_t_ = tf.tanh(self.c_t_, name='c_t_')\n",
    "        \n",
    "        # Combine forget and input gates to update cell state\n",
    "        with tf.name_scope(\"update_cell_state\"):\n",
    "            self.c_t_f = tf.multiply(self.cell_state, self.f_t, name='c_t_f') \n",
    "            self.c_t_i = tf.multiply(self.c_t_, self.i_t, name='c_t_i') \n",
    "            self.c_t = tf.add(self.c_t_f, self.c_t_i, name='c_t')\n",
    "        \n",
    "        # Output gate\n",
    "        with tf.name_scope(\"output_gate\"):\n",
    "            self.W_o = tf.Variable(tf.truncated_normal([num_hidden +  input_size, num_hidden]),\n",
    "                                   name='W_o')\n",
    "            self.b_o = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name='b_o')\n",
    "            self.o_t = tf.matmul(tf.concat([self.hidden_state, self.x], 1), self.W_o) + self.b_o\n",
    "            self.o_t = tf.sigmoid(self.o_t, name='o_t')\n",
    "        \n",
    "        # Gate tanh(cell state) with output gate to update hidden state (output)\n",
    "        with tf.name_scope(\"update_hidden_state\"):\n",
    "            self.h_t = tf.multiply(tf.tanh(self.c_t), self.o_t, name='h_t')\n",
    "        \n",
    "        # tf session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def step(self, x):\n",
    "        # shape(x) = [batch_size, input_size] at time t\n",
    "        # Compute output and new state\n",
    "        h, c = self.sess.run([self.h_t, self.c_t], \n",
    "                             feed_dict={self.x: x,\n",
    "                                        self.hidden_state: self.current_hidden_state, \n",
    "                                        self.cell_state: self.current_cell_state})\n",
    "        # Update current states\n",
    "        self.current_hidden_state = h\n",
    "        self.current_cell_state = c\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def out(self, X):\n",
    "        # Reset state to zero state\n",
    "        self.current_hidden_state = self.zero_state\n",
    "        self.current_cell_state = self.zero_state\n",
    "        \n",
    "        # Pass batch input x_t for each time step t\n",
    "        H = []\n",
    "        for i in range(X.shape[1]):\n",
    "            H.append(self.step(X[:, i, ...]))\n",
    "        \n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states:\n",
      "[[ 0.36249086  0.03932692  0.03911257]\n",
      " [ 0.20759627  0.2687242  -0.01895547]]\n",
      "[[ 0.10290282 -0.02434576 -0.03873252]\n",
      " [ 0.14209694  0.2538662  -0.0651268 ]]\n",
      "[[ 0.23239931 -0.05251402  0.01512763]\n",
      " [ 0.23350267  0.22753493 -0.03943847]]\n",
      "[[ 0.17305562 -0.07541554 -0.06053226]\n",
      " [ 0.33283624  0.10467365  0.08489635]]\n",
      "[[ 0.39625847  0.02193981  0.01964775]\n",
      " [ 0.18227693  0.02154228  0.03121651]]\n",
      "\n",
      "current hidden state:\n",
      "[[ 0.39625847  0.02193981  0.01964775]\n",
      " [ 0.18227693  0.02154228  0.03121651]]\n",
      "\n",
      "current cell state:\n",
      "[[ 0.51729691  0.02303421  0.05977021]\n",
      " [ 0.26779944  0.02440291  0.07869279]]\n"
     ]
    }
   ],
   "source": [
    "# Set up RNN cell\n",
    "tf.reset_default_graph()\n",
    "batch_size = 2\n",
    "trace_length = 5\n",
    "input_size = 4\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, trace_length, input_size])\n",
    "num_hidden = 3\n",
    "rnn = LSTM_cell(x, num_hidden)\n",
    "\n",
    "# Same test run\n",
    "x = np.random.random([batch_size, trace_length, input_size]) \n",
    "h = rnn.out(x)\n",
    "print(\"hidden states:\")\n",
    "for h_t in h: print(h_t)\n",
    "print(\"\\ncurrent hidden state:\")\n",
    "print(rnn.current_hidden_state)\n",
    "print(\"\\ncurrent cell state:\")\n",
    "print(rnn.current_cell_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing tf graph\n",
    "Note: this may only work in Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit: https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter/38192374#38192374\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.8761629910688349&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 4\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x_t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 4\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cell_state&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden_state&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;forget_gate/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;forget_gate/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;forget_gate/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;forget_gate/truncated_normal/mul&quot;\\n  input: &quot;forget_gate/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/W_f&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/W_f/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;forget_gate/W_f&quot;\\n  input: &quot;forget_gate/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@forget_gate/W_f&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/W_f/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;forget_gate/W_f&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@forget_gate/W_f&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/b_f&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/b_f/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;forget_gate/b_f&quot;\\n  input: &quot;forget_gate/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@forget_gate/b_f&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/b_f/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;forget_gate/b_f&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@forget_gate/b_f&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;hidden_state&quot;\\n  input: &quot;x_t&quot;\\n  input: &quot;forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;forget_gate/concat&quot;\\n  input: &quot;forget_gate/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;forget_gate/MatMul&quot;\\n  input: &quot;forget_gate/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;input_gate/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;input_gate/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;input_gate/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;input_gate/truncated_normal/mul&quot;\\n  input: &quot;input_gate/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/W_i&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/W_i/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;input_gate/W_i&quot;\\n  input: &quot;input_gate/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_gate/W_i&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/W_i/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;input_gate/W_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_gate/W_i&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/b_i&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/b_i/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;input_gate/b_i&quot;\\n  input: &quot;input_gate/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_gate/b_i&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/b_i/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;input_gate/b_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_gate/b_i&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;hidden_state&quot;\\n  input: &quot;x_t&quot;\\n  input: &quot;input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;input_gate/concat&quot;\\n  input: &quot;input_gate/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;input_gate/MatMul&quot;\\n  input: &quot;input_gate/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;candidate_values/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;candidate_values/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;candidate_values/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;candidate_values/truncated_normal/mul&quot;\\n  input: &quot;candidate_values/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/W_c&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/W_c/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;candidate_values/W_c&quot;\\n  input: &quot;candidate_values/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@candidate_values/W_c&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/W_c/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;candidate_values/W_c&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@candidate_values/W_c&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/b_c&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/b_c/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;candidate_values/b_c&quot;\\n  input: &quot;candidate_values/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@candidate_values/b_c&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/b_c/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;candidate_values/b_c&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@candidate_values/b_c&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;hidden_state&quot;\\n  input: &quot;x_t&quot;\\n  input: &quot;candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;candidate_values/concat&quot;\\n  input: &quot;candidate_values/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;candidate_values/MatMul&quot;\\n  input: &quot;candidate_values/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;cell_state&quot;\\n  input: &quot;forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;candidate_values/c_t_&quot;\\n  input: &quot;input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;update_cell_state/c_t_f&quot;\\n  input: &quot;update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;output_gate/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;output_gate/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;output_gate/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output_gate/truncated_normal/mul&quot;\\n  input: &quot;output_gate/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/W_o&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/W_o/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output_gate/W_o&quot;\\n  input: &quot;output_gate/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_gate/W_o&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/W_o/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output_gate/W_o&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_gate/W_o&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/b_o&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/b_o/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output_gate/b_o&quot;\\n  input: &quot;output_gate/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_gate/b_o&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/b_o/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output_gate/b_o&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_gate/b_o&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;hidden_state&quot;\\n  input: &quot;x_t&quot;\\n  input: &quot;output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;output_gate/concat&quot;\\n  input: &quot;output_gate/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output_gate/MatMul&quot;\\n  input: &quot;output_gate/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;update_hidden_state/Tanh&quot;\\n  input: &quot;output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^forget_gate/W_f/Assign&quot;\\n  input: &quot;^forget_gate/b_f/Assign&quot;\\n  input: &quot;^input_gate/W_i/Assign&quot;\\n  input: &quot;^input_gate/b_i/Assign&quot;\\n  input: &quot;^candidate_values/W_c/Assign&quot;\\n  input: &quot;^candidate_values/b_c/Assign&quot;\\n  input: &quot;^output_gate/W_o/Assign&quot;\\n  input: &quot;^output_gate/b_o/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.8761629910688349&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Unrolling the network\n",
    "The graph above looks good, but instead of iterating through a `for` loop to compute each time step, let's unroll the network to compute the output at all time steps at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_layer: \n",
    "    def __init__(self, x, num_hidden, activation='tanh'):\n",
    "        # Get input shape\n",
    "        input_shape = x.get_shape().as_list()\n",
    "        self.batch_size = input_shape[0]\n",
    "        trace_length = input_shape[1]\n",
    "        self.input_size = input_shape[2] # assume flattened\n",
    "        self.x = x\n",
    "        x_series = tf.unstack(x, axis=1)\n",
    "        \n",
    "        # Zero state\n",
    "        self.zero_state = np.zeros([batch_size, num_hidden])\n",
    "        self.init_hidden_state = tf.placeholder(tf.float32,\n",
    "                                                shape=[batch_size, num_hidden],\n",
    "                                                name='init_hidden_state')\n",
    "        self.init_cell_state = tf.placeholder(tf.float32,\n",
    "                                              shape=[batch_size, num_hidden],\n",
    "                                              name='init_cell_state')\n",
    "        \n",
    "        # Create shared parameters\n",
    "        with tf.name_scope(\"params\"):\n",
    "            self.W_f = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_f')\n",
    "            self.b_f = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_f\")\n",
    "            self.W_i = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_i')\n",
    "            self.b_i = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_i\")\n",
    "            self.W_c = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_c')\n",
    "            self.b_c = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_c\")\n",
    "            self.W_o = tf.Variable(tf.truncated_normal([num_hidden +  input_size, num_hidden]),\n",
    "                                   name='W_o')\n",
    "            self.b_o = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name='b_o')\n",
    "        \n",
    "        # Unroll network by creating (trace_length) LSTM cells\n",
    "        h_t = self.init_hidden_state\n",
    "        c_t = self.init_cell_state\n",
    "        self.outputs = []\n",
    "        for t, x_t in enumerate(x_series):\n",
    "            h_t, c_t = self.LSTM_cell(x_t, h_t, c_t, scope=\"Cell_%d\" % t)\n",
    "            self.outputs.append(h_t)\n",
    "        \n",
    "        # tf session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def LSTM_cell(self, x_t, hidden_state, cell_state, scope=\"Cell\"):\n",
    "        with tf.name_scope(scope):\n",
    "            # Forget gate\n",
    "            with tf.name_scope(\"forget_gate\"):\n",
    "                W_f = self.W_f # vs. tf.identity(self.W_f)\n",
    "                b_f = self.b_f # vs. tf.identity(self.b_f)\n",
    "                f_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_f) + b_f\n",
    "                f_t = tf.sigmoid(f_t, name='f_t')\n",
    "\n",
    "            # Input gate\n",
    "            with tf.name_scope(\"input_gate\"):\n",
    "                W_i = self.W_i\n",
    "                b_i = self.b_i\n",
    "                i_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_i) + b_i\n",
    "                i_t = tf.sigmoid(i_t, name='i_t')\n",
    "\n",
    "\n",
    "            # New cell state candidate values\n",
    "            with tf.name_scope(\"candidate_values\"):\n",
    "                W_c = self.W_c\n",
    "                b_c = self.b_c\n",
    "                c_t_ = tf.matmul(tf.concat([hidden_state, x_t], 1), W_c) + b_c\n",
    "                c_t_ = tf.tanh(c_t_, name='c_t_')\n",
    "\n",
    "            # Combine forget and input gates to update cell state\n",
    "            with tf.name_scope(\"update_cell_state\"):\n",
    "                c_t_f = tf.multiply(cell_state, f_t, name='c_t_f') \n",
    "                c_t_i = tf.multiply(c_t_, i_t, name='c_t_i') \n",
    "                c_t = tf.add(c_t_f, c_t_i, name='c_t')\n",
    "\n",
    "            # Output gate\n",
    "            with tf.name_scope(\"output_gate\"):\n",
    "                W_o = self.W_o\n",
    "                b_o = self.b_o\n",
    "                o_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_o) + b_o\n",
    "                o_t = tf.sigmoid(o_t, name='o_t')\n",
    "\n",
    "            # Gate tanh(cell state) with output gate to update hidden state (output)\n",
    "            with tf.name_scope(\"update_hidden_state\"):\n",
    "                h_t = tf.multiply(tf.tanh(c_t), o_t, name='h_t')\n",
    "\n",
    "            return h_t, c_t\n",
    "    \n",
    "    def out(self, X):\n",
    "        feed_dict = {self.x: X,\n",
    "                     self.init_hidden_state: self.zero_state,\n",
    "                     self.init_cell_state: self.zero_state}\n",
    "        return self.sess.run(self.outputs, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states:\n",
      "[[-0.07845152 -0.0468897  -0.12943874]\n",
      " [ 0.02393308  0.01062461  0.01333745]]\n",
      "[[-0.18784374 -0.04632721 -0.15332571]\n",
      " [ 0.13834111 -0.04746186 -0.08977975]]\n",
      "[[-0.30638924 -0.14702731 -0.2577512 ]\n",
      " [ 0.10506167 -0.11854228 -0.17134102]]\n",
      "[[-0.38088018 -0.01861375 -0.27257231]\n",
      " [ 0.19053105 -0.08923865 -0.26499707]]\n",
      "[[-0.40826714  0.09289505 -0.21621533]\n",
      " [ 0.17739724 -0.09497022 -0.2219989 ]]\n"
     ]
    }
   ],
   "source": [
    "# Set up RNN cell\n",
    "tf.reset_default_graph()\n",
    "batch_size = 2\n",
    "trace_length = 5\n",
    "input_size = 4\n",
    "x = tf.placeholder(tf.float32, \n",
    "                   shape=[batch_size, trace_length, input_size],\n",
    "                   name='input_series')\n",
    "num_hidden = 3\n",
    "rnn = LSTM_layer(x, num_hidden)\n",
    "\n",
    "# Same test run\n",
    "x = np.random.random([batch_size, trace_length, input_size]) \n",
    "h = rnn.out(x)\n",
    "print(\"hidden states:\")\n",
    "for h_t in h: print(h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.9457453197801575&quot;).pbtxt = 'node {\\n  name: &quot;input_series&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 4\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;input_series&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init_hidden_state&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init_cell_state&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;params/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;params/truncated_normal/mul&quot;\\n  input: &quot;params/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_f&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_f/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/W_f&quot;\\n  input: &quot;params/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_f&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_f/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/W_f&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_f&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_f&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_f/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/b_f&quot;\\n  input: &quot;params/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_f&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_f/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/b_f&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_f&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;params/truncated_normal_1/TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_1/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;params/truncated_normal_1/mul&quot;\\n  input: &quot;params/truncated_normal_1/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_i&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_i/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/W_i&quot;\\n  input: &quot;params/truncated_normal_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_i&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_i/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/W_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_i&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_i&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_i/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/b_i&quot;\\n  input: &quot;params/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_i&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_i/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/b_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_i&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;params/truncated_normal_2/TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_2/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;params/truncated_normal_2/mul&quot;\\n  input: &quot;params/truncated_normal_2/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_c&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_c/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/W_c&quot;\\n  input: &quot;params/truncated_normal_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_c&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_c/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/W_c&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_c&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_c&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_c/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/b_c&quot;\\n  input: &quot;params/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_c&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_c/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/b_c&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_c&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_3/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;params/truncated_normal_3/TruncatedNormal&quot;\\n  input: &quot;params/truncated_normal_3/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/truncated_normal_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;params/truncated_normal_3/mul&quot;\\n  input: &quot;params/truncated_normal_3/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_o&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_o/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/W_o&quot;\\n  input: &quot;params/truncated_normal_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_o&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/W_o/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/W_o&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/W_o&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_o&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_o/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;params/b_o&quot;\\n  input: &quot;params/Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_o&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;params/b_o/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;params/b_o&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@params/b_o&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;init_hidden_state&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;Cell_0/forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_0/forget_gate/concat&quot;\\n  input: &quot;params/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_0/forget_gate/MatMul&quot;\\n  input: &quot;params/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_0/forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;init_hidden_state&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;Cell_0/input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_0/input_gate/concat&quot;\\n  input: &quot;params/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_0/input_gate/MatMul&quot;\\n  input: &quot;params/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_0/input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;init_hidden_state&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;Cell_0/candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_0/candidate_values/concat&quot;\\n  input: &quot;params/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_0/candidate_values/MatMul&quot;\\n  input: &quot;params/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_0/candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;init_cell_state&quot;\\n  input: &quot;Cell_0/forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_0/candidate_values/c_t_&quot;\\n  input: &quot;Cell_0/input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_0/update_cell_state/c_t_f&quot;\\n  input: &quot;Cell_0/update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;init_hidden_state&quot;\\n  input: &quot;unstack&quot;\\n  input: &quot;Cell_0/output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_0/output_gate/concat&quot;\\n  input: &quot;params/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_0/output_gate/MatMul&quot;\\n  input: &quot;params/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_0/output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_0/update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_0/update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_0/update_hidden_state/Tanh&quot;\\n  input: &quot;Cell_0/output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_0/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;Cell_1/forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_1/forget_gate/concat&quot;\\n  input: &quot;params/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_1/forget_gate/MatMul&quot;\\n  input: &quot;params/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_1/forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_0/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;Cell_1/input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_1/input_gate/concat&quot;\\n  input: &quot;params/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_1/input_gate/MatMul&quot;\\n  input: &quot;params/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_1/input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_0/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;Cell_1/candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_1/candidate_values/concat&quot;\\n  input: &quot;params/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_1/candidate_values/MatMul&quot;\\n  input: &quot;params/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_1/candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_0/update_cell_state/c_t&quot;\\n  input: &quot;Cell_1/forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_1/candidate_values/c_t_&quot;\\n  input: &quot;Cell_1/input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_1/update_cell_state/c_t_f&quot;\\n  input: &quot;Cell_1/update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_0/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:1&quot;\\n  input: &quot;Cell_1/output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_1/output_gate/concat&quot;\\n  input: &quot;params/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_1/output_gate/MatMul&quot;\\n  input: &quot;params/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_1/output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_1/update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_1/update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_1/update_hidden_state/Tanh&quot;\\n  input: &quot;Cell_1/output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_1/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:2&quot;\\n  input: &quot;Cell_2/forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_2/forget_gate/concat&quot;\\n  input: &quot;params/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_2/forget_gate/MatMul&quot;\\n  input: &quot;params/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_2/forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_1/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:2&quot;\\n  input: &quot;Cell_2/input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_2/input_gate/concat&quot;\\n  input: &quot;params/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_2/input_gate/MatMul&quot;\\n  input: &quot;params/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_2/input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_1/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:2&quot;\\n  input: &quot;Cell_2/candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_2/candidate_values/concat&quot;\\n  input: &quot;params/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_2/candidate_values/MatMul&quot;\\n  input: &quot;params/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_2/candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_1/update_cell_state/c_t&quot;\\n  input: &quot;Cell_2/forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_2/candidate_values/c_t_&quot;\\n  input: &quot;Cell_2/input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_2/update_cell_state/c_t_f&quot;\\n  input: &quot;Cell_2/update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_1/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:2&quot;\\n  input: &quot;Cell_2/output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_2/output_gate/concat&quot;\\n  input: &quot;params/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_2/output_gate/MatMul&quot;\\n  input: &quot;params/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_2/output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_2/update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_2/update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_2/update_hidden_state/Tanh&quot;\\n  input: &quot;Cell_2/output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_2/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:3&quot;\\n  input: &quot;Cell_3/forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_3/forget_gate/concat&quot;\\n  input: &quot;params/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_3/forget_gate/MatMul&quot;\\n  input: &quot;params/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_3/forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_2/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:3&quot;\\n  input: &quot;Cell_3/input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_3/input_gate/concat&quot;\\n  input: &quot;params/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_3/input_gate/MatMul&quot;\\n  input: &quot;params/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_3/input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_2/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:3&quot;\\n  input: &quot;Cell_3/candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_3/candidate_values/concat&quot;\\n  input: &quot;params/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_3/candidate_values/MatMul&quot;\\n  input: &quot;params/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_3/candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_2/update_cell_state/c_t&quot;\\n  input: &quot;Cell_3/forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_3/candidate_values/c_t_&quot;\\n  input: &quot;Cell_3/input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_3/update_cell_state/c_t_f&quot;\\n  input: &quot;Cell_3/update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_2/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:3&quot;\\n  input: &quot;Cell_3/output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_3/output_gate/concat&quot;\\n  input: &quot;params/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_3/output_gate/MatMul&quot;\\n  input: &quot;params/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_3/output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_3/update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_3/update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_3/update_hidden_state/Tanh&quot;\\n  input: &quot;Cell_3/output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/forget_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/forget_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_3/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:4&quot;\\n  input: &quot;Cell_4/forget_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/forget_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_4/forget_gate/concat&quot;\\n  input: &quot;params/W_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/forget_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_4/forget_gate/MatMul&quot;\\n  input: &quot;params/b_f/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/forget_gate/f_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_4/forget_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/input_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/input_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_3/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:4&quot;\\n  input: &quot;Cell_4/input_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/input_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_4/input_gate/concat&quot;\\n  input: &quot;params/W_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/input_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_4/input_gate/MatMul&quot;\\n  input: &quot;params/b_i/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/input_gate/i_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_4/input_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/candidate_values/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/candidate_values/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_3/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:4&quot;\\n  input: &quot;Cell_4/candidate_values/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/candidate_values/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_4/candidate_values/concat&quot;\\n  input: &quot;params/W_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/candidate_values/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_4/candidate_values/MatMul&quot;\\n  input: &quot;params/b_c/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/candidate_values/c_t_&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_4/candidate_values/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/update_cell_state/c_t_f&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_3/update_cell_state/c_t&quot;\\n  input: &quot;Cell_4/forget_gate/f_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/update_cell_state/c_t_i&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_4/candidate_values/c_t_&quot;\\n  input: &quot;Cell_4/input_gate/i_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/update_cell_state/c_t&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_4/update_cell_state/c_t_f&quot;\\n  input: &quot;Cell_4/update_cell_state/c_t_i&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/output_gate/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/output_gate/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Cell_3/update_hidden_state/h_t&quot;\\n  input: &quot;unstack:4&quot;\\n  input: &quot;Cell_4/output_gate/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/output_gate/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Cell_4/output_gate/concat&quot;\\n  input: &quot;params/W_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/output_gate/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Cell_4/output_gate/MatMul&quot;\\n  input: &quot;params/b_o/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/output_gate/o_t&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Cell_4/output_gate/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/update_hidden_state/Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Cell_4/update_cell_state/c_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cell_4/update_hidden_state/h_t&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cell_4/update_hidden_state/Tanh&quot;\\n  input: &quot;Cell_4/output_gate/o_t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^params/W_f/Assign&quot;\\n  input: &quot;^params/b_f/Assign&quot;\\n  input: &quot;^params/W_i/Assign&quot;\\n  input: &quot;^params/b_i/Assign&quot;\\n  input: &quot;^params/W_c/Assign&quot;\\n  input: &quot;^params/b_c/Assign&quot;\\n  input: &quot;^params/W_o/Assign&quot;\\n  input: &quot;^params/b_o/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.9457453197801575&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing backprop\n",
    "The previous networks were only defined for the forward passes. In order to train them, we need to implement some form of backpropagation through time (BPTT). Rather than backpropagating entire sequences, which can be thousands to tens of thousands steps, backpropagation is often \"cut off\" after some specified length in a process termed \"truncated backpropagation\". Say you have a sequence of length $n$ with a truncated backpropagation length of $m$. Every $k_1$ timesteps, truncated backprogation performs BPTT for $k_2$ timesteps. There are two basic approaches:\n",
    "\n",
    "1) Set $k_1=k_2$. That is, if BPTT is truncated to 10 timesteps backward, then BPTT is only performed every 10 timesteps. In other words, for a sequence $\\{x_1, \\ldots, x_n\\}$, the network learns from sequences $\\{x_1, \\ldots, x_m\\}, \\{x_{m+1}, \\ldots, x_{2m}\\}, \\ldots, \\{x_{n-m}, \\ldots, x_n\\}$. This is the approach that TensorFlow uses.\n",
    "\n",
    "2) Set $k_1=1$. That is, perform BPTT every timestep, regardless of BPTT length. In other words, for a sequence $\\{x_1, \\ldots, x_n\\}$, the network learns from sequences $\\{x_1, \\ldots, x_m\\}, \\{x_2, \\ldots, x_{m+1}\\}, \\ldots, \\{x_{n-m}, \\ldots, x_n\\}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define the class to build the graph, not perform computations\n",
    "class LSTM_layer: \n",
    "    def __init__(self, x, num_hidden, activation='tanh'):\n",
    "        # Get input shape\n",
    "        input_shape = x.get_shape().as_list()\n",
    "        self.batch_size = input_shape[0]\n",
    "        trace_length = input_shape[1]\n",
    "        self.input_size = input_shape[2] # assume flattened\n",
    "        x_series = tf.unstack(x, axis=1)\n",
    "        \n",
    "        # Initial states\n",
    "        self.init_hidden_state = tf.placeholder(tf.float32,\n",
    "                                                shape=[batch_size, num_hidden],\n",
    "                                                name='init_hidden_state')\n",
    "        self.init_cell_state = tf.placeholder(tf.float32,\n",
    "                                              shape=[batch_size, num_hidden],\n",
    "                                              name='init_cell_state')\n",
    "        \n",
    "        # Create shared parameters\n",
    "        with tf.name_scope(\"params\"):\n",
    "            self.W_f = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_f')\n",
    "            self.b_f = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_f\")\n",
    "            self.W_i = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_i')\n",
    "            self.b_i = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_i\")\n",
    "            self.W_c = tf.Variable(tf.truncated_normal([num_hidden + input_size, num_hidden]),\n",
    "                                   name='W_c')\n",
    "            self.b_c = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name=\"b_c\")\n",
    "            self.W_o = tf.Variable(tf.truncated_normal([num_hidden +  input_size, num_hidden]),\n",
    "                                   name='W_o')\n",
    "            self.b_o = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_hidden]),\n",
    "                                   name='b_o')\n",
    "        \n",
    "        # Unroll network by creating (trace_length) LSTM cells\n",
    "        h_t = self.init_hidden_state\n",
    "        c_t = self.init_cell_state\n",
    "        self.hidden_states = []\n",
    "        self.cell_states = []\n",
    "        for t, x_t in enumerate(x_series):\n",
    "            h_t, c_t = self.LSTM_cell(x_t, h_t, c_t, scope=\"Cell_%d\" % t)\n",
    "            self.hidden_states.append(h_t)\n",
    "            self.cell_states.append(c_t)\n",
    "        \n",
    "    def LSTM_cell(self, x_t, hidden_state, cell_state, scope=\"Cell\"):\n",
    "        with tf.name_scope(scope):\n",
    "            # Forget gate\n",
    "            with tf.name_scope(\"forget_gate\"):\n",
    "                W_f = self.W_f # vs. tf.identity(self.W_f)\n",
    "                b_f = self.b_f # vs. tf.identity(self.b_f)\n",
    "                f_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_f) + b_f\n",
    "                f_t = tf.sigmoid(f_t, name='f_t')\n",
    "\n",
    "            # Input gate\n",
    "            with tf.name_scope(\"input_gate\"):\n",
    "                W_i = self.W_i\n",
    "                b_i = self.b_i\n",
    "                i_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_i) + b_i\n",
    "                i_t = tf.sigmoid(i_t, name='i_t')\n",
    "\n",
    "\n",
    "            # New cell state candidate values\n",
    "            with tf.name_scope(\"candidate_values\"):\n",
    "                W_c = self.W_c\n",
    "                b_c = self.b_c\n",
    "                c_t_ = tf.matmul(tf.concat([hidden_state, x_t], 1), W_c) + b_c\n",
    "                c_t_ = tf.tanh(c_t_, name='c_t_')\n",
    "\n",
    "            # Combine forget and input gates to update cell state\n",
    "            with tf.name_scope(\"update_cell_state\"):\n",
    "                c_t_f = tf.multiply(cell_state, f_t, name='c_t_f') \n",
    "                c_t_i = tf.multiply(c_t_, i_t, name='c_t_i') \n",
    "                c_t = tf.add(c_t_f, c_t_i, name='c_t')\n",
    "\n",
    "            # Output gate\n",
    "            with tf.name_scope(\"output_gate\"):\n",
    "                W_o = self.W_o\n",
    "                b_o = self.b_o\n",
    "                o_t = tf.matmul(tf.concat([hidden_state, x_t], 1), W_o) + b_o\n",
    "                o_t = tf.sigmoid(o_t, name='o_t')\n",
    "\n",
    "            # Gate tanh(cell state) with output gate to update hidden state (output)\n",
    "            with tf.name_scope(\"update_hidden_state\"):\n",
    "                h_t = tf.multiply(tf.tanh(c_t), o_t, name='h_t')\n",
    "\n",
    "            return h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:\n",
      "[[ 0.54066342  0.45933658]]\n",
      "[[ 0.53943419  0.46056589]]\n",
      "[[ 0.54027724  0.4597227 ]]\n",
      "labels:\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "losses:\n",
      "0.777972\n",
      "0.775299\n",
      "0.615673\n"
     ]
    }
   ],
   "source": [
    "# Set up input\n",
    "tf.reset_default_graph()\n",
    "batch_size = 1\n",
    "trace_length = 3\n",
    "input_size = 4\n",
    "x = tf.placeholder(tf.float32, \n",
    "                   shape=[batch_size, trace_length, input_size],\n",
    "                   name='input_series')\n",
    "\n",
    "# Add RNN cell\n",
    "num_hidden = 3\n",
    "rnn = LSTM_layer(x, num_hidden)\n",
    "\n",
    "# Add simple softmax output layer\n",
    "preds = []\n",
    "num_output = 2\n",
    "W_p = tf.Variable(tf.truncated_normal([num_hidden, num_output]), name='W_p')\n",
    "b_p = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_output]), name='b_p')\n",
    "with tf.name_scope(\"preds\"):\n",
    "    for h_t in rnn.hidden_states:\n",
    "        preds.append(tf.nn.softmax(tf.matmul(h_t, W_p) + b_p))\n",
    "\n",
    "# Add loss function\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, trace_length, num_output], \n",
    "                         name='y')\n",
    "y_series = tf.unstack(y, axis=1)\n",
    "losses = []\n",
    "with tf.name_scope(\"losses\"):\n",
    "    for i, [pred_t, y_t] in enumerate(zip(preds, y_series)):\n",
    "        with tf.name_scope(\"loss_%d\" % i):\n",
    "            losses.append(tf.reduce_sum(-y_t * tf.log(pred_t)))\n",
    "    total_loss = tf.reduce_mean(losses, name='total_loss')\n",
    "\n",
    "# Add optimizer\n",
    "optimizer = tf.train.RMSPropOptimizer(0.1)\n",
    "train_step = optimizer.minimize(total_loss)\n",
    "    \n",
    "# Grab gradients for interest\n",
    "    \n",
    "    \n",
    "# Add session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Sample backpropagation step\n",
    "x_batch = np.random.random([batch_size, trace_length, input_size])\n",
    "y_batch = np.random.random([batch_size, trace_length, num_output])\n",
    "y_batch[:, :, 1] = 1 - y_batch[:, :, 0]\n",
    "y_batch = (y_batch > 0.5).astype(int) # creates one-hot vectors\n",
    "zero_state = np.zeros([batch_size, num_hidden])\n",
    "feed_dict = {x: x_batch,\n",
    "             rnn.init_hidden_state: zero_state,\n",
    "             rnn.init_cell_state: zero_state,\n",
    "             y: y_batch}\n",
    "preds_batch, losses_batch, _ = sess.run([preds, losses, train_step], \n",
    "                                        feed_dict=feed_dict)\n",
    "print(\"preds:\")\n",
    "for p in preds_batch: print(p)\n",
    "\n",
    "print(\"labels:\")\n",
    "for y_t in y_batch: print(y_t)\n",
    "    \n",
    "print(\"losses:\")\n",
    "for l in losses_batch: print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the gradients that TensorFlow is calculating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try when you dare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it on some toy data set. Let's use the Echo-RNN set from [this blog post](https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(total_series_length, echo_step, batch_size, trace_length):\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, ))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50000 into shape (5,15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3082bbc97aa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecho_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mecho_step\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    230\u001b[0m            [5, 6]])\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 50000 into shape (5,15)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "total_series_length = 50000\n",
    "trace_length = 15\n",
    "input_size = 1\n",
    "num_hidden = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length // batch_size // trace_length\n",
    "\n",
    "# Set up input\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, \n",
    "                   shape=[batch_size, trace_length, input_size],\n",
    "                   name='input_series')\n",
    "\n",
    "# Add RNN cell\n",
    "num_hidden = 3\n",
    "rnn = LSTM_layer(x, num_hidden)\n",
    "\n",
    "# Add simple softmax output layer\n",
    "preds = []\n",
    "num_output = 2\n",
    "W_p = tf.Variable(tf.truncated_normal([num_hidden, num_output]), name='W_p')\n",
    "b_p = tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[1, num_output]), name='b_p')\n",
    "with tf.name_scope(\"preds\"):\n",
    "    for h_t in rnn.hidden_states:\n",
    "        preds.append(tf.nn.softmax(tf.matmul(h_t, W_p) + b_p))\n",
    "\n",
    "# Add loss function\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, trace_length, num_output], \n",
    "                         name='y')\n",
    "y_series = tf.unstack(y, axis=1)\n",
    "losses = []\n",
    "with tf.name_scope(\"losses\"):\n",
    "    for i, [pred_t, y_t] in enumerate(zip(preds, y_series)):\n",
    "        with tf.name_scope(\"loss_%d\" % i):\n",
    "            losses.append(tf.reduce_sum(-y_t * tf.log(pred_t)))\n",
    "    total_loss = tf.reduce_mean(losses, name='total_loss')\n",
    "\n",
    "# Add optimizer\n",
    "optimizer = tf.train.RMSPropOptimizer(0.1)\n",
    "train_step = optimizer.minimize(total_loss)\n",
    "    \n",
    "# Grab gradients for interest\n",
    "    \n",
    "    \n",
    "# Add session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training\n",
    "current_hidden_state = np.zeros([batch_size, num_hidden])\n",
    "current_cell_state = np.zeros([batch_size, num_hidden])\n",
    "for epoch in range(num_epochs):\n",
    "    # Get data\n",
    "    x_batch = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y_batch = np.roll(x_batch, echo_step)\n",
    "    y_batch[0:echo_step] = 0\n",
    "    x_batch = np.reshape(x_batch, [batch_size, trace_length])\n",
    "    y_batch = y_batch.reshape([batch_size, trace_length])\n",
    "\n",
    "    # Train step\n",
    "    feed_dict = {x: x_batch,\n",
    "                 rnn.init_hidden_state: current_hidden_state,\n",
    "                 rnn.init_cell_state: current_cell_state,\n",
    "                 y: y_batch}\n",
    "    current_hidden_state, current_cell_state, total_loss_, _ \\\n",
    "        = sess.run([rnn.hidden_states[-1], rnn.cell_states[-1], total_loss, train_step], \n",
    "                   feed_dict=feed_dict)                         \n",
    "\n",
    "    print(\"Epoch: %d, loss: %.2f\" % (total_loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
