{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../python/\")\n",
    "from memory.ReplayMemory import ReplayMemory\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: [58  8 24 44 72 70 19]\n",
      "Slices:\n",
      " [58 59 60 61 62  8  9 10 11 12 24 25 26 27 28 44 45 46 47 48 72 73 74 75 76\n",
      " 70 71 72 73 74 19 20 21 22 23]\n",
      "Corrected slices:\n",
      " [58 59 60 61 62  8  9 10 11 12 24 25 26 27 28 44 45 46 47 48 72 73 74 75 76\n",
      " 70 71 72 73 74 19 20 21 22 23]\n",
      "Original:\n",
      "s1[0].shape: (100, 12, 84, 84)\n",
      "s1[0][slices][0, ...]:\n",
      "[[ 0.53546728  0.34858874  0.99254931]\n",
      " [ 0.98171926  0.22050952  0.32387461]\n",
      " [ 0.50426754  0.38082718  0.53164911]]\n",
      "s1[0][slices][5, ...]:\n",
      "[[ 0.90396477  0.21205504  0.47445172]\n",
      " [ 0.63509333  0.78279289  0.96300232]\n",
      " [ 0.17780579  0.22307001  0.1404238 ]]\n",
      "Reshape:\n",
      "s1[0][slices].shape: (7, 5, 12, 84, 84)\n",
      "s1[0][slices][0][...]:\n",
      "[[ 0.53546728  0.34858874  0.99254931]\n",
      " [ 0.98171926  0.22050952  0.32387461]\n",
      " [ 0.50426754  0.38082718  0.53164911]]\n",
      "s1[0][slices][1][...]:\n",
      "[[ 0.90396477  0.21205504  0.47445172]\n",
      " [ 0.63509333  0.78279289  0.96300232]\n",
      " [ 0.17780579  0.22307001  0.1404238 ]]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, 100, 7)\n",
    "print(\"idx:\", idx)\n",
    "\n",
    "x, y = np.meshgrid(idx, np.arange(5))\n",
    "slices = np.transpose(x + y).flatten()\n",
    "print(\"Slices:\\n\", slices)\n",
    "slices %= 100\n",
    "print(\"Corrected slices:\\n\", slices)\n",
    "\n",
    "s1_0 = np.random.rand(100, 12, 84, 84) # mimics memory with capacity 100\n",
    "s1_1 = np.random.rand(2)\n",
    "s1 = [s1_0, s1_1]\n",
    "print(\"Original:\")\n",
    "print(\"s1[0].shape:\", s1[0].shape)\n",
    "print(\"s1[0][slices][0, ...]:\")\n",
    "print(s1[0][slices][0, 0, :3, :3])\n",
    "print(\"s1[0][slices][5, ...]:\")\n",
    "print(s1[0][slices][5, 0, :3, :3])\n",
    "\n",
    "rs = np.reshape(s1[0][slices], [7, 5, 12, 84, 84]) # [num of traj, traj len, state_shape...]\n",
    "print(\"Reshape:\")\n",
    "print(\"s1[0][slices].shape:\", rs.shape)\n",
    "print(\"s1[0][slices][0][...]:\")\n",
    "print(rs[0, 0, 0, :3, :3])\n",
    "print(\"s1[0][slices][1][...]:\")\n",
    "print(rs[1, 0, 0, :3, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse order\n",
    "Applicable for class without reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[ 0.08736947  0.26904687  0.18850901  0.15742123  0.14138586  0.10484942\n",
      "  0.29992704  0.22221412  0.57461042  0.80538772  0.00261921  0.22227756\n",
      "  0.20479822  0.9082098   0.57885134  0.35208548  0.84299166  0.9774215\n",
      "  0.64349928  0.30795383  0.56341805  0.89320403  0.51121639  0.31188183\n",
      "  0.72205378  0.2704125   0.41581256  0.55601417  0.59611474  0.86199004]\n",
      "a[[lists]]:\n",
      "[ 0.14138586  0.80538772  0.57885134  0.30795383  0.72205378  0.86199004]\n",
      "a[fancy indexing]:\n",
      "[ 0.14138586  0.80538772  0.57885134  0.30795383  0.72205378  0.86199004]\n",
      "Reverse order:\n",
      "[ 0.14138586  0.80538772  0.57885134  0.30795383  0.72205378  0.86199004]\n",
      "[ 0.15742123  0.57461042  0.9082098   0.64349928  0.31188183  0.59611474]\n",
      "[ 0.18850901  0.22221412  0.20479822  0.9774215   0.51121639  0.55601417]\n",
      "[ 0.26904687  0.29992704  0.22227756  0.84299166  0.89320403  0.41581256]\n",
      "[ 0.08736947  0.10484942  0.00261921  0.35208548  0.56341805  0.2704125 ]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(30)\n",
    "print(\"a:\")\n",
    "print(a)\n",
    "print(\"a[[lists]]:\")\n",
    "print(a[[4, 9, 14, 19, 24, 29]])\n",
    "print(\"a[fancy indexing]:\")\n",
    "print(a[4::5])\n",
    "print(\"Reverse order:\")\n",
    "for i in range(5)[::-1]: \n",
    "    print(a[i::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "w = np.transpose(np.tile(np.arange(4), [5, 1])).flatten()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "w = np.transpose(np.tile(np.arange(4), [1, 1])).flatten()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping into [# of trajectories, trajectory length, ...]\n",
    "I like the way this is organized and that the Replay Memory class is doing some of the dirty work. However, this is incompatible with other forms of replay memory, in which the shape is [batch_size, ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryReplayMemory(ReplayMemory):\n",
    "    def __init__(self, capacity, state_shape, num_game_var, input_overlap=0, \n",
    "                 trajectory_length=5):\n",
    "        # Initialize base replay memory\n",
    "        ReplayMemory.__init__(self, capacity, state_shape, num_game_var, input_overlap)\n",
    "\n",
    "        # Initialize trajectory parameters\n",
    "        self.tr_len = trajectory_length\n",
    "        \n",
    "    def get_sample(self, sample_size):\n",
    "        # Get random minibatch of indices\n",
    "        idx = np.random.randint(0, self.size, sample_size)\n",
    "        x, y = np.meshgrid(idx, np.arange(self.tr_len))\n",
    "        idx = np.transpose(x + y).flatten() # [i, i+1, ..., i+n, j, j+1, ..., j+n, k...]\n",
    "        idx %= self.capacity # wrap end cases\n",
    "        t = self.tr_len\n",
    "        # TODO: find isterminal in sequences and cut short\n",
    "        \n",
    "        # s = [screen[trajectory id, trajectory step, state_shape...], gv[traj id, traj step, num_gv]]\n",
    "        \n",
    "        # Make list of states\n",
    "        s1_sample, s2_sample = [], []\n",
    "\n",
    "        # Get screen component\n",
    "        s1_slice = self.s1[0][idx]\n",
    "        if self.overlap > 0:\n",
    "            # Stack overlapping frames from s1 to stored frames of s2 to\n",
    "            # recreate full s2 state\n",
    "            s2_slice = np.concatenate((self.s1[0][[idx] + [slice(None)] * self.chdim \n",
    "                                             + [slice(None, self.overlap)]], \n",
    "                                             self.s2[0][idx]), \n",
    "                                            axis=self.chdim+1)\n",
    "        else:\n",
    "            s2_slice = self.s2[0][idx]\n",
    "        s1_sample.append(np.reshape(s1_slice, [sample_size, t] + self.state_shape))\n",
    "        s2_sample.append(np.reshape(s2_slice, [sample_size, t] + self.state_shape))\n",
    "\n",
    "        # Get game variable component\n",
    "        s1_sample.append(np.reshape(self.s1[1][idx], [sample_size, t] + [self.num_game_var]))\n",
    "        s2_sample.append(np.reshape(self.s2[1][idx], [sample_size, t] + [self.num_game_var]))\n",
    "\n",
    "        # Get other transition parameters\n",
    "        a_sample = np.reshape(self.a[idx], [sample_size, t])\n",
    "        isterminal_sample = np.reshape(self.isterminal[idx], [sample_size, t])\n",
    "        r_sample = np.reshape(self.r[idx], [sample_size, t])\n",
    "\n",
    "        # Return importance sampling weights of one (stochastic distribution)\n",
    "        w = np.ones([sample_size, t])\n",
    "\n",
    "        return s1_sample, a_sample, s2_sample, isterminal_sample, r_sample, w, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = 100\n",
    "state_shape = [12, 84, 84]\n",
    "num_game_var = 2\n",
    "input_overlap = 3\n",
    "trajectory_length = 10\n",
    "memory = TrajectoryReplayMemory(capacity=capacity,\n",
    "                                state_shape=state_shape,\n",
    "                                num_game_var=num_game_var,\n",
    "                                input_overlap=input_overlap,\n",
    "                                trajectory_length=trajectory_length)\n",
    "terminal_states = random.sample(range(capacity), 7)\n",
    "s1, s2 = [], []\n",
    "s2.append(np.random.rand(state_shape[0], state_shape[1], state_shape[2]))\n",
    "s2.append([random.random()] * num_game_var)\n",
    "for i in range(capacity):\n",
    "    s1 = [s2[0], s2[1]]\n",
    "    s2[0] = np.delete(s2[0], np.s_[0:input_overlap], axis=0)\n",
    "    s2[0] = np.append(s2[0], np.random.rand(input_overlap, state_shape[1], state_shape[2]), axis=0)\n",
    "    s2[1] = [random.random()] * num_game_var\n",
    "    a = random.sample(range(4), 1)[0]\n",
    "    r = random.random()\n",
    "    isterminal = i in terminal_states\n",
    "    memory.add_transition(s1, a, s2, isterminal, r)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: [ 1  2  3  4  5  6  7  8  9 10 64 65 66 67 68 69 70 71 72 73 95 96 97 98 99\n",
      "  0  1  2  3  4 77 78 79 80 81 82 83 84 85 86 26 27 28 29 30 31 32 33 34 35\n",
      " 87 88 89 90 91 92 93 94 95 96  4  5  6  7  8  9 10 11 12 13]\n",
      "s1[0].shape: (7, 10, 12, 84, 84)\n",
      "s1[1].shape: (7, 10, 2)\n",
      "a.shape: (7, 10)\n",
      "s2[0].shape: (7, 10, 12, 84, 84)\n",
      "s2[1].shape: (7, 10, 2)\n",
      "isterminal.shape: (7, 10)\n",
      "r.shape: (7, 10)\n",
      "w.shape: (7, 10)\n"
     ]
    }
   ],
   "source": [
    "s1, a, s2, isterminal, r, w, idx = memory.get_sample(7)\n",
    "print(\"idx:\", idx)\n",
    "print(\"s1[0].shape:\", s1[0].shape)\n",
    "print(\"s1[1].shape:\", s1[1].shape)\n",
    "print(\"a.shape:\", a.shape)\n",
    "print(\"s2[0].shape:\", s2[0].shape)\n",
    "print(\"s2[1].shape:\", s2[1].shape)\n",
    "print(\"isterminal.shape:\", isterminal.shape)\n",
    "print(\"r.shape:\", r.shape)\n",
    "print(\"w.shape:\", w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No reshaping, [batch_size, ...]\n",
    "This returns experiences in the form [batch_size, ...], where batch_size = (# of trajectories, i.e. sample_size) * (trajectory length). This form is compatible with current Replay Memory classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrajectoryReplayMemory(ReplayMemory):\n",
    "    def __init__(self, capacity, state_shape, num_game_var, input_overlap=0, \n",
    "                 trajectory_length=5):\n",
    "        # Initialize base replay memory\n",
    "        ReplayMemory.__init__(self, capacity, state_shape, num_game_var, input_overlap)\n",
    "\n",
    "        # Initialize trajectory parameters\n",
    "        self.tr_len = trajectory_length\n",
    "        \n",
    "    def get_sample(self, sample_size):\n",
    "        # Get random minibatch of indices\n",
    "        idx = np.random.randint(0, self.size, sample_size)\n",
    "        x, y = np.meshgrid(idx, np.arange(self.tr_len))\n",
    "        idx = np.transpose(x + y).flatten() # [i, i+1, ..., i+n, j, j+1, ..., j+n, k...]\n",
    "        idx %= self.capacity # wrap end cases\n",
    "        t = self.tr_len\n",
    "        # TODO: find isterminal in sequences and cut short\n",
    "          \n",
    "        # Make list of states\n",
    "        s1_sample, s2_sample = [], []\n",
    "\n",
    "        # Get screen component\n",
    "        s1_slice = self.s1[0][idx]\n",
    "        if self.overlap > 0:\n",
    "            # Stack overlapping frames from s1 to stored frames of s2 to\n",
    "            # recreate full s2 state\n",
    "            s2_slice = np.concatenate((self.s1[0][[idx] + [slice(None)] * self.chdim \n",
    "                                             + [slice(None, self.overlap)]], \n",
    "                                             self.s2[0][idx]), \n",
    "                                            axis=self.chdim+1)\n",
    "        else:\n",
    "            s2_slice = self.s2[0][idx]\n",
    "        s1_sample.append(s1_slice)\n",
    "        s2_sample.append(s2_slice)\n",
    "\n",
    "        # Get game variable component\n",
    "        s1_sample.append(self.s1[1][idx])\n",
    "        s2_sample.append(self.s2[1][idx])\n",
    "\n",
    "        # Get other transition parameters\n",
    "        a_sample = self.a[idx]\n",
    "        isterminal_sample = self.isterminal[idx]\n",
    "        r_sample = self.r[idx]\n",
    "\n",
    "        # Return importance sampling weights of one (stochastic distribution)\n",
    "        w = np.ones([sample_size * t])\n",
    "\n",
    "        return s1_sample, a_sample, s2_sample, isterminal_sample, r_sample, w, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capacity = 100\n",
    "state_shape = [12, 84, 84]\n",
    "num_game_var = 2\n",
    "input_overlap = 3\n",
    "trajectory_length = 10\n",
    "memory = TrajectoryReplayMemory(capacity=capacity,\n",
    "                                state_shape=state_shape,\n",
    "                                num_game_var=num_game_var,\n",
    "                                input_overlap=input_overlap,\n",
    "                                trajectory_length=trajectory_length)\n",
    "terminal_states = random.sample(range(capacity), 7)\n",
    "s1, s2 = [], []\n",
    "s2.append(np.random.rand(state_shape[0], state_shape[1], state_shape[2]))\n",
    "s2.append([random.random()] * num_game_var)\n",
    "for i in range(capacity):\n",
    "    s1 = [s2[0], s2[1]]\n",
    "    s2[0] = np.delete(s2[0], np.s_[0:input_overlap], axis=0)\n",
    "    s2[0] = np.append(s2[0], np.random.rand(input_overlap, state_shape[1], state_shape[2]), axis=0)\n",
    "    s2[1] = [random.random()] * num_game_var\n",
    "    a = random.sample(range(4), 1)[0]\n",
    "    r = random.random()\n",
    "    isterminal = i in terminal_states\n",
    "    memory.add_transition(s1, a, s2, isterminal, r)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: [46 47 48 49 50 51 52 53 54 55 78 79 80 81 82 83 84 85 86 87 42 43 44 45 46\n",
      " 47 48 49 50 51 77 78 79 80 81 82 83 84 85 86 84 85 86 87 88 89 90 91 92 93\n",
      " 90 91 92 93 94 95 96 97 98 99 24 25 26 27 28 29 30 31 32 33]\n",
      "s1[0].shape: (70, 12, 84, 84)\n",
      "s1[1].shape: (70, 2)\n",
      "a.shape: (70,)\n",
      "s2[0].shape: (70, 12, 84, 84)\n",
      "s2[1].shape: (70, 2)\n",
      "isterminal.shape: (70,)\n",
      "r.shape: (70,)\n",
      "w.shape: (70,)\n"
     ]
    }
   ],
   "source": [
    "s1, a, s2, isterminal, r, w, idx = memory.get_sample(7)\n",
    "print(\"idx:\", idx)\n",
    "print(\"s1[0].shape:\", s1[0].shape)\n",
    "print(\"s1[1].shape:\", s1[1].shape)\n",
    "print(\"a.shape:\", a.shape)\n",
    "print(\"s2[0].shape:\", s2[0].shape)\n",
    "print(\"s2[1].shape:\", s2[1].shape)\n",
    "print(\"isterminal.shape:\", isterminal.shape)\n",
    "print(\"r.shape:\", r.shape)\n",
    "print(\"w.shape:\", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (7, 12, 84, 84) (7, 2)\n"
     ]
    }
   ],
   "source": [
    "sample = [s1[0][6::10], s1[1][6::10]]\n",
    "print(len(sample), sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If using one or multiple GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from helper import create_agent\n",
    "import tensorflow as tf\n",
    "from vizdoom import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializes DoomGame from config file\n",
    "def initialize_vizdoom(config_file):\n",
    "    print(\"Initializing doom... \", end=\"\"), sys.stdout.flush()\n",
    "    game = DoomGame()\n",
    "    game.load_config(config_file)\n",
    "    game.set_window_visible(True)\n",
    "    game.init()\n",
    "    print(\"Done.\")\n",
    "    return game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom... Done.\n",
      "\n",
      "Mapping of agent states --> network states:\n",
      "screen --> Tensor(\"main_network/screen:0\", shape=(?, 84, 84, 3), dtype=float32)\n",
      "[GameVariable.HEALTH] --> Tensor(\"main_network/health:0\", shape=(?, 1), dtype=float32)\n",
      "[GameVariable.VELOCITY_X, GameVariable.VELOCITY_Y] --> Tensor(\"main_network/velocity:0\", shape=(?, 2), dtype=float32)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "agent_file_path = \"./trajectory_experience_replay/standard.json\"\n",
    "config_file_path = \"../config/open_field.cfg\"\n",
    "results_dir = \"./trajectory_experience_replay/results\"\n",
    "\n",
    "game = initialize_vizdoom(config_file_path)\n",
    "agent = create_agent(agent_file_path,\n",
    "                     game=game, \n",
    "                     params_file=None,\n",
    "                     action_set=None,\n",
    "                     output_directory=results_dir,\n",
    "                     train_mode=True)\n",
    "\n",
    "agent.initialize_new_episode()\n",
    "for i in range(500): # memory capacity set to 100\n",
    "    agent.perform_learning_step(1, 100)\n",
    "    if game.is_episode_finished():\n",
    "        agent.initialize_new_episode()\n",
    "game.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prioritized experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom... Done.\n",
      "\n",
      "Mapping of agent states --> network states:\n",
      "screen --> Tensor(\"main_network/screen:0\", shape=(?, 84, 84, 3), dtype=float32)\n",
      "[GameVariable.HEALTH] --> Tensor(\"main_network/health:0\", shape=(?, 1), dtype=float32)\n",
      "[GameVariable.VELOCITY_X, GameVariable.VELOCITY_Y] --> Tensor(\"main_network/velocity:0\", shape=(?, 2), dtype=float32)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "agent_file_path = \"./trajectory_experience_replay/prioritized.json\"\n",
    "config_file_path = \"../config/open_field.cfg\"\n",
    "results_dir = \"./trajectory_experience_replay/results\"\n",
    "\n",
    "game = initialize_vizdoom(config_file_path)\n",
    "agent = create_agent(agent_file_path,\n",
    "                     game=game, \n",
    "                     params_file=None,\n",
    "                     action_set=None,\n",
    "                     output_directory=results_dir,\n",
    "                     train_mode=True)\n",
    "\n",
    "agent.initialize_new_episode()\n",
    "for i in range(250): # memory capacity set to 100\n",
    "    agent.perform_learning_step(1, 100)\n",
    "    if game.is_episode_finished():\n",
    "        agent.initialize_new_episode()\n",
    "game.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...Done.\n",
      "Calculating probs...Done.\n",
      "Plotting...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAIMCAYAAADIN5BFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgAAgKEIsgAAAAxFkAUAAGAo/x9VErI0Ql/0jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60275ccd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get samples\n",
    "tr_len = agent.memory.tr_len\n",
    "batch_size = 5\n",
    "num_batches = 10000\n",
    "t = []\n",
    "print(\"Sampling...\", end=\"\"), sys.stdout.flush()\n",
    "for i in range(num_batches):\n",
    "    s1, a, s2, isterminal, r, w, t_i = agent.memory.get_sample(batch_size)\n",
    "    t.append(t_i[tr_len-1::tr_len])\n",
    "print(\"Done.\"), sys.stdout.flush()\n",
    "\n",
    "t = np.asarray(t)\n",
    "\n",
    "# Count how many times each\n",
    "heap = agent.memory.heap\n",
    "start_pos = agent.memory.start_pos\n",
    "capacity = agent.memory.capacity\n",
    "sample_size = 100\n",
    "p_tot = heap[1]\n",
    "calc_prob = np.zeros(sample_size)\n",
    "actual_prob = np.zeros(sample_size)\n",
    "print(\"Calculating probs...\", end=\"\"), sys.stdout.flush()\n",
    "for j, i in enumerate(range(capacity)):\n",
    "    p = heap[start_pos + i]\n",
    "    calc_prob[j] = p / p_tot\n",
    "    actual_prob[j] = np.sum(np.count_nonzero(t == i)) / t.size\n",
    "    #print(\"Transition %d: calculated prob=%.3f, actual prob=%.3f\" % (i, calc_prob, actual_prob))\n",
    "print(\"Done.\"), sys.stdout.flush()\n",
    "\n",
    "print(\"Plotting...\"), sys.stdout.flush()\n",
    "fig, ax = plt.subplots()\n",
    "idx = np.arange(sample_size)\n",
    "width = 0.3\n",
    "ax.bar(idx, calc_prob, width, color=\"orange\")\n",
    "ax.bar(idx + width, actual_prob, width, color=\"black\")\n",
    "fig.set_size_inches(16, 9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
