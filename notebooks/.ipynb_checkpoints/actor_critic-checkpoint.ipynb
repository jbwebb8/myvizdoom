{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "from helper import create_agent\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If running other experiments on GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializes DoomGame from config file\n",
    "def initialize_vizdoom(config_file):\n",
    "    game = DoomGame()\n",
    "    game.load_config(config_file)\n",
    "    game.init()\n",
    "    return game  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize agent and TensorFlow graph\n",
    "def make_new_agent():\n",
    "    tf.reset_default_graph()\n",
    "    agent_file_path = \"./actor_critic/ac.json\"\n",
    "    config_file_path = \"./actor_critic/ac.cfg\"\n",
    "    results_dir = \"./actor_critic/results_dir\"\n",
    "    action_set = \"basic_three\"\n",
    "    game = initialize_vizdoom(config_file_path)\n",
    "    return create_agent(agent_file_path,\n",
    "                        game=game, \n",
    "                        action_set=action_set,\n",
    "                        output_directory=results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-step learning\n",
    "First, we will walk through the n-step learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prints status of memory buffers\n",
    "def print_agent_status():\n",
    "    print(\"s1_buffer:    \\n\", agent.s1_buffer[:, :5, 0, -1])\n",
    "    print(\"a_buffer:     \\n\", agent.a_buffer)\n",
    "    print(\"s2_buffer:    \\n\", agent.s2_buffer[:, :5, 0, -1])\n",
    "    print(\"r_buffer:     \\n\", agent.r_buffer)\n",
    "    print(\"gamma_buffer: \\n\", agent.gamma_buffer)\n",
    "    print(\"memory r:     \\n\", agent.memory.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: \n",
      "s1_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a_buffer:     \n",
      " [2 0 0 0 0]\n",
      "s2_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "r_buffer:     \n",
      " [-0.04  0.    0.    0.    0.  ]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "Step 2: \n",
      "s1_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a_buffer:     \n",
      " [2 2 0 0 0]\n",
      "s2_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04  0.    0.    0.  ]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "Step 3: \n",
      "s1_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a_buffer:     \n",
      " [2 2 2 0 0]\n",
      "s2_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04  0.    0.  ]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "Step 4: \n",
      "s1_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a_buffer:     \n",
      " [2 2 2 1 0]\n",
      "s2_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04  0.  ]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "Step 5: \n",
      "s1_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]]\n",
      "a_buffer:     \n",
      " [2 2 2 1 1]\n",
      "s2_buffer:    \n",
      " [[ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 0.96059601  1.          0.99        0.9801      0.970299  ]\n",
      "memory r:     \n",
      " [ 0.02110773  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "\n",
      "V(s):  [[ 0.22833839]]\n"
     ]
    }
   ],
   "source": [
    "# View memory storage\n",
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "for i in range(5):\n",
    "    print(\"Step %d: \" % (i+1))\n",
    "    agent.perform_learning_step(1, 1)\n",
    "    print_agent_status()\n",
    "    print()\n",
    "print(\"V(s): \", agent.network.get_value_output(agent.s2_buffer[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, during the first $n$ steps, the agent stores transitions consisting of $s1, a, s2, r$. After the $n$th step, the return $R$ can be calculated for time $t-n$. The first $Q(s,a) \\approx \\mathbb{E}[R_t]$ is given by:\n",
    "\n",
    "$\\sum_{i=0}^{k-1}(\\gamma^ir_i)+\\gamma^kV(s_t)$\n",
    "\n",
    "which in this case is vectorized:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "1.0\n",
    "\\\\ 0.99\n",
    "\\\\ 0.9801\n",
    "\\\\ 0.970299\n",
    "\\\\ 0.96059601\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "-0.04\n",
    "\\\\ -0.04\n",
    "\\\\ -0.04\n",
    "\\\\ -0.04\n",
    "\\\\ -0.04\n",
    "\\end{bmatrix}\n",
    "+ 0.99^5V(s_5) = -0.196 + (0.951)(0.228338) = 0.0211$\n",
    "\n",
    "which matches the initial return placed in memory. The $s1, s2, a, r$ buffers roll to the beginning, placing the next transition at slot 0, while the $\\gamma$ buffer rolls forward by one slot to match the new configuration. Now for the next five steps, we should see a transition added after each learning step, updating the $r$ array in memory as calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: \n",
      "s1_buffer:    \n",
      " [[ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]]\n",
      "a_buffer:     \n",
      " [1 2 2 1 1]\n",
      "s2_buffer:    \n",
      " [[ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 0.970299    0.96059601  1.          0.99        0.9801    ]\n",
      "memory r:     \n",
      " [ 0.02110773  0.03489357  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "V(s):  [[ 0.24283469]] \n",
      "\n",
      "Step 7: \n",
      "s1_buffer:    \n",
      " [[ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.47058824  0.46568626  0.47058824  0.47058824  0.41549021]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]]\n",
      "a_buffer:     \n",
      " [1 0 2 1 1]\n",
      "s2_buffer:    \n",
      " [[ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.49019608  0.56078434  0.49019608  0.47058824  0.34901962]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 0.9801      0.970299    0.96059601  1.          0.99      ]\n",
      "memory r:     \n",
      " [ 0.02110773  0.03489357 -0.04599142  0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "V(s):  [[ 0.15778123]] \n",
      "\n",
      "Step 8: \n",
      "s1_buffer:    \n",
      " [[ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.49019608  0.56078434  0.49019608  0.47058824  0.34901962]\n",
      " [ 0.49990195  0.4509804   0.47058824  0.44549018  0.40000001]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]]\n",
      "a_buffer:     \n",
      " [1 0 0 1 1]\n",
      "s2_buffer:    \n",
      " [[ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.49019608  0.56078434  0.49019608  0.47058824  0.34901962]\n",
      " [ 0.41470587  0.41617647  0.43823528  0.43656862  0.3617647 ]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 0.99        0.9801      0.970299    0.96059601  1.        ]\n",
      "memory r:     \n",
      " [ 0.02110773  0.03489357 -0.04599142  0.05962786  0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "V(s):  [[ 0.26884368]] \n",
      "\n",
      "Step 9: \n",
      "s1_buffer:    \n",
      " [[ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.49019608  0.56078434  0.49019608  0.47058824  0.34901962]\n",
      " [ 0.41470587  0.41617647  0.43823528  0.43656862  0.3617647 ]\n",
      " [ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]]\n",
      "a_buffer:     \n",
      " [1 0 0 1 1]\n",
      "s2_buffer:    \n",
      " [[ 0.49225491  0.43235293  0.41127452  0.49117646  0.59019607]\n",
      " [ 0.49019608  0.56078434  0.49019608  0.47058824  0.34901962]\n",
      " [ 0.41470587  0.41617647  0.43823528  0.43656862  0.3617647 ]\n",
      " [ 0.40000001  0.46620914  0.43176469  0.40771243  0.39267975]\n",
      " [ 0.4509804   0.37450981  0.41274509  0.62352943  0.54509807]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.02110773  0.03489357 -0.04599142  0.05962786  0.03615659  0.          0.\n",
      "  0.          0.          0.        ]\n",
      "V(s):  [[ 0.2441628]] \n",
      "\n",
      "Step 10: \n",
      "s1_buffer:    \n",
      " [[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "a_buffer:     \n",
      " [0 0 0 0 0]\n",
      "s2_buffer:    \n",
      " [[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "r_buffer:     \n",
      " [ 0.  0.  0.  0.  0.]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [ 0.02110773  0.03489357 -0.04599142  0.05962786  0.03615659 -0.04       -0.0796\n",
      " -0.118804   -0.15761596 -0.1960398 ]\n",
      "V(s):  [[ 0.02561042]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now view adding transition to memory\n",
    "for i in range(5):\n",
    "    print(\"Step %d: \" % (i+6))\n",
    "    agent.perform_learning_step(1, 1)\n",
    "    print_agent_status()\n",
    "    print(\"V(s): \", agent.network.get_value_output(agent.s2_buffer[i]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next four transitions, the returns are calculated as above. For example, in step 6, the return is:\n",
    "\n",
    "$R_2 = -1.96 + (0.951)(0.242835) = 0.0349$\n",
    "\n",
    "Note that the $\\gamma$ buffer is displayed after it has been updated; thus, the buffer shown for the previous step represents the buffer used in the current calculation. Additionally, because the episode times out after 10 actions (40 tics), during step 10, the agent encounters a terminal state in s2; thus after calculating the last $n$ transitions, the buffers are reset, which is displayed in step 10. The returns for the last $n$ states are given as:\n",
    "\n",
    "$R_{T-i}=\\sum_{i=0}^{n} \\gamma^i r_{t-i}$\n",
    "\n",
    "or recursively:\n",
    "\n",
    "$R_t \\leftarrow r_t + \\gamma R_{t+1}$\n",
    "\n",
    "which in this case, because all rewards were $-0.04$, is simply:\n",
    "\n",
    "$R_{T-i}=\\sum_{i=0}^{n} \\gamma^i (-0.04) = (-0.04)\\sum_{i=0}^{n} \\gamma^i$\n",
    "\n",
    "Due to the recursive formula, the transitions are added in reverse order, as seen in the last 5 slots of the memory matrix $r$ above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing transitions into memory\n",
    "Now that we know the agent is properly calculating the n-step return of states, we need to make sure that the other variables ($s1, a, s2, isterminal$) are being properly associated with these returns in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_memory_status():\n",
    "    print(\"s1: \", agent.memory.s1[:, :5, 0, -1]) # due to storage of overlapping states\n",
    "    print(\"a:  \", agent.memory.a)\n",
    "    print(\"s2: \", agent.memory.s2[:, :5, 0, 0])\n",
    "    print(\"R:  \", agent.memory.r)\n",
    "    print(\"isterminal: \", agent.memory.isterminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 30, 45, 4)\n",
      "(10, 30, 45, 1)\n",
      "s1_buffer:    \n",
      " [[ 0.46557733  0.48518518  0.50230938  0.47058824  0.42763618]\n",
      " [ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]]\n",
      "a_buffer:     \n",
      " [0 1 2 1 2]\n",
      "s2_buffer:    \n",
      " [[ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]\n",
      " [ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 0.96059601  1.          0.99        0.9801      0.970299  ]\n",
      "memory r:     \n",
      " [-0.17756607  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "s1:  [[ 0.46557733  0.48518518  0.50230938  0.47058824  0.42763618]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a:   [0 0 0 0 0 0 0 0 0 0]\n",
      "s2:  [[ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "R:   [-0.17756607  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "isterminal:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Load memory with transitions\n",
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "print(agent.memory.s1.shape)\n",
    "print(agent.memory.s2.shape)\n",
    "for i in range(5):\n",
    "    agent.perform_learning_step(1, 1)\n",
    "\n",
    "# Compare current status with replay memory\n",
    "print_agent_status()\n",
    "print_memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the next transitions $(t,...,T-2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1_buffer:    \n",
      " [[ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]\n",
      " [ 0.45473856  0.51831156  0.4509804   0.4509804   0.34901962]\n",
      " [ 0.47058824  0.48962963  0.48007625  0.4516122   0.3685621 ]\n",
      " [ 0.5260784   0.52156866  0.40000001  0.52156866  0.54509807]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]]\n",
      "a_buffer:     \n",
      " [0 0 0 2 2]\n",
      "s2_buffer:    \n",
      " [[ 0.45473856  0.51831156  0.4509804   0.4509804   0.34901962]\n",
      " [ 0.47058824  0.48962963  0.48007625  0.4516122   0.3685621 ]\n",
      " [ 0.5260784   0.52156866  0.40000001  0.52156866  0.54509807]\n",
      " [ 0.44149238  0.40000001  0.69411767  0.54509807  0.47058824]\n",
      " [ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]]\n",
      "r_buffer:     \n",
      " [-0.04 -0.04 -0.04 -0.04 -0.04]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [-0.17756607 -0.16151434 -0.11614615 -0.15517615 -0.1869307   0.          0.\n",
      "  0.          0.          0.        ]\n",
      "s1:  [[ 0.46557733  0.48518518  0.50230938  0.47058824  0.42763618]\n",
      " [ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "a:   [0 1 2 1 2 0 0 0 0 0]\n",
      "s2:  [[ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]\n",
      " [ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "R:   [-0.17756607 -0.16151434 -0.11614615 -0.15517615 -0.1869307   0.          0.\n",
      "  0.          0.          0.        ]\n",
      "isterminal:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    agent.perform_learning_step(1, 1)\n",
    "\n",
    "# Compare current status with replay memory\n",
    "print_agent_status()\n",
    "print_memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally to the terminal step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1_buffer:    \n",
      " [[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "a_buffer:     \n",
      " [0 0 0 0 0]\n",
      "s2_buffer:    \n",
      " [[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "r_buffer:     \n",
      " [ 0.  0.  0.  0.  0.]\n",
      "gamma_buffer: \n",
      " [ 1.          0.99        0.9801      0.970299    0.96059601]\n",
      "memory r:     \n",
      " [-0.17756607 -0.16151434 -0.11614615 -0.15517615 -0.1869307  -0.04       -0.0796\n",
      " -0.118804   -0.15761596 -0.1960398 ]\n",
      "s1:  [[ 0.46557733  0.48518518  0.50230938  0.47058824  0.42763618]\n",
      " [ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]\n",
      " [ 0.44149238  0.40000001  0.69411767  0.54509807  0.47058824]\n",
      " [ 0.5260784   0.52156866  0.40000001  0.52156866  0.54509807]\n",
      " [ 0.47058824  0.48962963  0.48007625  0.4516122   0.3685621 ]\n",
      " [ 0.45473856  0.51831156  0.4509804   0.4509804   0.34901962]\n",
      " [ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]]\n",
      "a:   [0 1 2 1 2 2 2 0 0 0]\n",
      "s2:  [[ 0.4559913   0.47058824  0.47058824  0.45254901  0.43845317]\n",
      " [ 0.40000001  0.40000001  0.40000001  0.40000001  0.40000001]\n",
      " [ 0.48007625  0.51218957  0.52156866  0.47058824  0.34901962]\n",
      " [ 0.39523965  0.41459695  0.40293029  0.36862746  0.39198259]\n",
      " [ 0.52156866  0.55385619  0.47503269  0.4509804   0.40000001]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.44149238  0.40000001  0.69411767  0.54509807  0.47058824]\n",
      " [ 0.5260784   0.52156866  0.40000001  0.52156866  0.54509807]\n",
      " [ 0.47058824  0.48962963  0.48007625  0.4516122   0.3685621 ]\n",
      " [ 0.45473856  0.51831156  0.4509804   0.4509804   0.34901962]]\n",
      "R:   [-0.17756607 -0.16151434 -0.11614615 -0.15517615 -0.1869307  -0.04       -0.0796\n",
      " -0.118804   -0.15761596 -0.1960398 ]\n",
      "isterminal:  [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Perform terminal learning step\n",
    "agent.perform_learning_step(1, 1)\n",
    "print_agent_status()\n",
    "print_memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy and value functions\n",
    "Next, we will look into the policy and value functions, analyzing both their output and loss functions, as well as the gradients derived from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_learning_step():\n",
    "    s1, a, s2, isterminal, R, w = agent.memory.get_sample(1)\n",
    "    print(\"s1: \", s1[:, :3, 1, 1])\n",
    "    print(\"a:  \", a)\n",
    "    print(\"R:  \", R)\n",
    "    print(\"w:  \", w)\n",
    "    print(\"V:  \", agent.network.get_value_output(s1))\n",
    "    print(\"pi: \", agent.network.get_policy_output(s1))\n",
    "    loss_pi, loss_v = agent.network.learn(s1, a, R, weights=w)\n",
    "    print(\"loss_pi: \", loss_pi, \" loss_v: \", loss_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1:  [[ 0.47058824  0.46568626  0.47058824]]\n",
      "a:   [1]\n",
      "R:   [-0.31398159]\n",
      "w:   [ 1.]\n",
      "V:   [[-0.11301116]]\n",
      "pi:  [[ 0.23030756  0.27955541  0.49013704]]\n",
      "loss_pi:  [[-0.26658764]]  loss_v:  0.0403891\n"
     ]
    }
   ],
   "source": [
    "# Load memory with transitions\n",
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "for i in range(10):\n",
    "    agent.perform_learning_step(1, 1)\n",
    "print_learning_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the loss calculations. The loss of the policy is given by:\n",
    "\n",
    "$L_{\\pi} = -log(\\pi(a_t|s_t))(R_t-V(s_t)) - \\beta H(\\pi(s_t))$\n",
    "\n",
    "where the entropy is $\\sum_{i}-\\pi(a_i|s_t)log(\\pi(a_i|s_t))$. For this transition, this becomes:\n",
    "\n",
    "$L_{\\pi} = −log(0.2796)(−0.3140−(−0.1130))+(0.01)((0.2303)log(0.2303) + (0.2796)log(0.2796) + (0.4901)log(0.4901) = -0.2666$\n",
    "\n",
    "The loss of the value function is simpler, as it just calculates the (mean) squared error:\n",
    "\n",
    "$L_{V} = \\sum_{i} (R_t - V(s_t))^2$\n",
    "\n",
    "which in this case becomes:\n",
    "\n",
    "$L_{V} = (-0.3140 - (-0.1130))^2 = 0.0404$\n",
    "\n",
    "Let's redefine the previous function to now include gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_learning_step():\n",
    "    # Get batch from memory\n",
    "    s1, a, s2, isterminal, R, w = agent.memory.get_sample(1)\n",
    "    s1 = agent.network._check_state(s1)\n",
    "    a = agent.network._check_actions(a)\n",
    "    if w is None:\n",
    "        w = np.ones(a.shape[0])\n",
    "        \n",
    "    # Print values of batch\n",
    "    print(\"s1: \", s1[:, :3, 1, 1])\n",
    "    print(\"a:  \", a)\n",
    "    print(\"R:  \", R)\n",
    "    print(\"w:  \", w)\n",
    "    print(\"V:  \", agent.network.get_value_output(s1))\n",
    "    print(\"pi: \", agent.network.get_policy_output(s1))\n",
    "    \n",
    "    # Get gradients prior to learning step (gradient descent)\n",
    "    opt = agent.network.optimizer\n",
    "    var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                 scope=agent.network.scope)\n",
    "    fd = {agent.network.state: s1, agent.network.actions: a, \n",
    "          agent.network.q_sa: R, agent.network.IS_weights: w}\n",
    "    sess = agent.network.sess\n",
    "    gvs_pi = opt.compute_gradients(agent.network.loss_pi, var_list=var_list)\n",
    "    grads_pi = sess.run([g for g, v in gvs_pi], feed_dict=fd)\n",
    "    gvs_v = opt.compute_gradients(agent.network.loss_v, var_list=var_list)\n",
    "    gvs_v = [[g, v] for g, v in gvs_v if g is not None]\n",
    "    grads_v = sess.run([g for g, v in gvs_v], feed_dict=fd)\n",
    "    \n",
    "    # Print fully-connected hidden layer output\n",
    "    fc = tf.get_default_graph().get_tensor_by_name(\"global_network/FC_1/Relu:0\")\n",
    "    print(\"FC_output: \", sess.run(fc[0, :5], feed_dict=fd))\n",
    "    \n",
    "    # Print losses and gradients\n",
    "    loss_pi, loss_v = agent.network.learn(s1, a, R, weights=w)\n",
    "    print(\"loss_pi: \", loss_pi, \" loss_v: \", loss_v)\n",
    "    print(\"d(loss_pi)/d(b_pi): %s\" % gvs_pi[-1][1].name[:-2], grads_pi[-1])\n",
    "    print(\"d(loss_pi)/d(w_pi): %s\" % gvs_pi[-2][1].name[:-2], grads_pi[-2][:5, :])\n",
    "    print(\"d(loss_pi)/d(b_V): %s\" % gvs_pi[-3][1].name[:-2], grads_pi[-3])\n",
    "    print(\"d(loss_V)/d(b_V): %s\" % gvs_v[-1][1].name[:-2], grads_v[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1:  [[ 0.41960785  0.45869282  0.41960785]]\n",
      "a:   [[0 1]]\n",
      "R:   [-0.1960398]\n",
      "w:   [ 1.]\n",
      "V:   [[ 0.63908535]]\n",
      "pi:  [[ 0.36095497  0.30637842  0.33266661]]\n",
      "FC_output:  [ 0.          0.14301239  0.11612199  0.04790126  0.        ]\n",
      "loss_pi:  [[-0.99886197]]  loss_v:  0.697434\n",
      "d(loss_pi)/d(b_pi): global_network/pi/biases [-0.30116326  0.57899565 -0.27783233]\n",
      "d(loss_pi)/d(w_pi): global_network/pi/weights [[ 0.          0.          0.        ]\n",
      " [-0.04307008  0.08280355 -0.03973347]\n",
      " [-0.03497168  0.06723412 -0.03226244]\n",
      " [-0.0144261   0.02773462 -0.01330852]\n",
      " [ 0.          0.          0.        ]]\n",
      "d(loss_pi)/d(b_V): global_network/V/biases [-1.18293428]\n",
      "d(loss_V)/d(b_V): global_network/V/biases [ 1.6702503]\n"
     ]
    }
   ],
   "source": [
    "# Load memory with transitions\n",
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "for i in range(10):\n",
    "    agent.perform_learning_step(1, 1)\n",
    "print_learning_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives of the loss functions are as follows:\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial \\pi(a|s_t)} = \n",
    "\\left\\{\\begin{matrix}\n",
    "   -\\dfrac{R_t - V(s_t)}{\\pi(a|s_t)} + \\beta (1 + log\\pi(a|s_t)) \\text{ if } a = a_t \\\\ \n",
    "   \\beta (1 + log\\pi(a|s_t)) \\text{ if } a \\neq a_t\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial V(s_t)} = log\\pi(a_t|s_t)$\n",
    "\n",
    "$\\dfrac{\\partial L_V}{\\partial \\pi(a|s_t)} = 0$\n",
    "\n",
    "$\\dfrac{\\partial L_V}{\\partial V(s_t)} = -2(R_t - V(s_t))$\n",
    "\n",
    "Additionally, due to the softmax activation in the $\\pi$ output layer, the derivatives for its biases and weights must backpropagate through the softmax function. Further, because of the summation term ($\\sum_i e^f_i$) in softmax, the derivatives $\\frac{\\partial \\pi(a_i|s_t)}{\\partial w_{\\pi(a_j|s_t)}}$, where $i \\neq j$, are nonzero. Therefore:\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial w_{\\pi(a_j|s_t)}}\n",
    "= \\dfrac{\\partial L_\\pi}{\\partial \\pi(s_t)} \\dfrac{\\partial \\pi(s_t)}{\\partial w_{\\pi(a_j|s_t)}}\n",
    "= \\sum_i \\left ( \\dfrac{\\partial L_\\pi}{\\partial \\pi(a_i|s_t)} \\dfrac{\\partial \\pi(a_i|s_t)}{\\partial w_{\\pi(a_j|s_t)}} \\right )$,\n",
    "\n",
    "where, for $f_k = b_{\\pi(a_k|s_t)} + w_{\\pi(a_k|s_t)}^{(1)}x^{(1)} + w_{\\pi(a_k|s_t)}^{(2)}x^{(2)} + \\cdots + w_{\\pi(a_k|s_t)}^{(n)}x^{(n)}$:\n",
    "\n",
    "$ \\dfrac{\\partial \\pi(a_i|s_t)}{\\partial b_{\\pi(a_j|s_t)}}\n",
    "= \\dfrac{\\partial}{\\partial b_{\\pi(a_j|s_t)}} \\left ( \\dfrac{e^f_i}{\\sum_k e^f_k} \\right )\n",
    "= \\dfrac{e^f_i \\dfrac{\\partial f_i}{\\partial b_{\\pi(a_j|s_t)}} \\left ( \\sum_k e^f_k \\right ) - e^f_i \\dfrac{\\partial}{\\partial b_{\\pi(a_j|s_t)}} \\left ( \\sum_k e^f_k \\right )}{\\left ( \\sum_k e^f_k \\right )^2} = \n",
    "\\left\\{\\begin{matrix}\n",
    "    \\dfrac{e^f_i \\sum_k e^f_k - e^{2f_i}}{\\left ( \\sum_k e^f_k \\right )^2} \n",
    "    = \\dfrac{e^f_i}{\\sum_k e^f_k} - \\left ( \\dfrac{e^f_i}{\\sum_k e^f_k} \\right )^2\n",
    "    = \\pi(a_i|s_t) - (\\pi(a_i|s_t))^2\n",
    "    = \\pi(a_i|s_t)(1 - \\pi(a_i|s_t)) \\text{ if } i = j \\\\\n",
    "    \\dfrac{(0) \\sum_k e^f_k - e^{f_i}e^{f_j}}{\\left ( \\sum_k e^f_k \\right )^2}\n",
    "    = \\left ( \\dfrac{e^f_i}{\\sum_k e^f_k} \\right ) \\left ( \\dfrac{e^f_j}{\\sum_k e^f_k} \\right )\n",
    "    = -\\pi(a_i|s_t)\\pi(a_j|s_t) \\text{ if } i \\neq j\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "Similarly, the expressions for $\\frac{\\partial \\pi(a_i|s_t)}{\\partial w_{\\pi(a_j|s_t)}^{(m)}}$ are the same as above except multiplied by $\\frac{\\partial f_j}{\\partial w_{\\pi(a_j|s_t)}^{(m)}} = x^{(m)}$:\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_i|s_t)}{\\partial b_{\\pi(a_j|s_t)}} =\n",
    "\\left\\{\\begin{matrix}\n",
    "    = x^{(m)}\\pi(a_i|s_t)(1 - \\pi(a_i|s_t)) \\text{ if } i = j \\\\\n",
    "    = -x^{(m)}\\pi(a_i|s_t)\\pi(a_j|s_t) \\text{ if } i \\neq j\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "First, let's check out loss functions again:\n",
    "\n",
    "$L_{\\pi} = −log(0.3064)(-0.1960 - 0.6391)+(0.01)((0.3610)log(0.3610) + (0.3064)log(0.3064) + (0.3327)log(0.3327) = -0.9988$\n",
    "\n",
    "$L_{V} = (-0.1960 - (0.6391))^2 = 0.6974$\n",
    "\n",
    "We can plug in the numbers above to check these values. The derivatives of the loss function with respect to softmax outputs are:\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial \\pi(a_0|s_t)} = (0.01)(1 + log(0.3610)) = -0.00019$\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial \\pi(a_1|s_t)} = -\\dfrac{-0.1960 - 0.6391}{0.3064} + (0.01)(1 + log(0.3064)) = 2.7237$\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial \\pi(a_2|s_t)} = (0.01)(1 + log(0.3327)) = -0.0010$\n",
    "\n",
    "and, in turn, the derivatives of the softmax outputs with respect to the output layer weights and biases are (for index 0):\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_0|s_t)}{\\partial b_{\\pi(a_0|s_t)}} = (0.3610)(1 - 0.3610) = 0.2307$\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_1|s_t)}{\\partial b_{\\pi(a_0|s_t)}} = -(0.3064)(0.3610) = -0.1106$\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_2|s_t)}{\\partial b_{\\pi(a_0|s_t)}} = -(0.3327)(0.3610) = -0.1201$\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_0|s_t)}{\\partial w_{\\pi(a_0|s_t)}^{(1)}} = (0.1430)(0.3610)(1 - 0.3610) = 0.03299$\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_1|s_t)}{\\partial w_{\\pi(a_0|s_t)}^{(1)}} = -(0.1430)(0.3064)(0.3610) = -0.01582$\n",
    "\n",
    "$\\dfrac{\\partial \\pi(a_2|s_t)}{\\partial w_{\\pi(a_0|s_t)}^{(1)}} = -(0.1430)(0.3327)(0.3610) = -0.01717$\n",
    "\n",
    "Finally, we sum the derivatives to get the total derivatives for each variable:\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial b_{\\pi(a_0|s_t)}} \n",
    "= \\sum_i \\left ( \\dfrac{\\partial L_\\pi}{\\partial \\pi(a_i|s_t)} \\dfrac{\\partial \\pi(a_i|s_t)}{\\partial b_{\\pi(a_0|s_t)}} \\right )\n",
    "= (-0.00019)(0.2307) + (2.7237)(-0.1106) + (-0.0010)(-0.1201) = -0.3012$\n",
    "\n",
    "$\\dfrac{\\partial L_\\pi}{\\partial w_{\\pi(a_0|s_t)}^{(1)}}\n",
    "= \\sum_i \\left ( \\dfrac{\\partial L_\\pi}{\\partial \\pi(a_i|s_t)} \\dfrac{\\partial \\pi(a_i|s_t)}{\\partial w_{\\pi(a_0|s_t)}^{(1)}} \\right )\n",
    "= (-0.00019)(0.03299) + (2.7237)(-0.01582) + (-0.0010)(-0.01717) = -0.04308$\n",
    "\n",
    "Great, everything matches up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Troubleshooting backprop\n",
    "After only a few hundred learning steps, the network weights diverge to `nan` almost all at once. I presume it must be due to some component of the loss function becoming infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "np.seterr(all='warn')\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_values_after_nan(s1):\n",
    "    print(\"V:  \", agent.network.get_value_output(s1))\n",
    "    print(\"pi: \", agent.network.get_policy_output(s1))\n",
    "    var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                 scope=agent.network.scope)\n",
    "    sess = agent.network.sess\n",
    "    for v in var_list:\n",
    "        values = sess.run(v)\n",
    "        if np.isnan(values).any():\n",
    "            print(v.name[:-2])\n",
    "            print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\r"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n\nCaused by op 'global_network/summaries/gradients/global_network/pi/biases/grads_0', defined at:\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-58-4f3bf23bcbd0>\", line 1, in <module>\n    agent = make_new_agent()\n  File \"<ipython-input-7-01f1c4964e8d>\", line 12, in make_new_agent\n    output_directory=results_dir)\n  File \"../python/helper.py\", line 17, in create_agent\n    return agent_types[agent_type](agent_file=agent_filename, **kwargs)\n  File \"../python/agent/ACERAgent.py\", line 25, in __init__\n    **kwargs)\n  File \"../python/agent/Agent.py\", line 82, in __init__\n    scope=self.MAIN_SCOPE)\n  File \"../python/helper.py\", line 25, in create_network\n    return network_types[net_type](network_file=network_filename, **kwargs)\n  File \"../python/network/ACNetwork.py\", line 20, in __init__\n    scope=scope)\n  File \"../python/network/Network.py\", line 77, in __init__\n    var_sum, neur_sum, grad_sum = builder.add_summaries()\n  File \"../python/network/NetworkBuilder.py\", line 273, in add_summaries\n    grad_sum.append(tf.summary.histogram(\"grads_%d\" % i, g))\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4f3bf23bcbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                agent.network.IS_weights: w}\n\u001b[1;32m     23\u001b[0m     grad_sum_ = sess.run(agent.network.grad_sum,\n\u001b[0;32m---> 24\u001b[0;31m                          feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_sum_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# throws error when grad is Nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n\nCaused by op 'global_network/summaries/gradients/global_network/pi/biases/grads_0', defined at:\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-58-4f3bf23bcbd0>\", line 1, in <module>\n    agent = make_new_agent()\n  File \"<ipython-input-7-01f1c4964e8d>\", line 12, in make_new_agent\n    output_directory=results_dir)\n  File \"../python/helper.py\", line 17, in create_agent\n    return agent_types[agent_type](agent_file=agent_filename, **kwargs)\n  File \"../python/agent/ACERAgent.py\", line 25, in __init__\n    **kwargs)\n  File \"../python/agent/Agent.py\", line 82, in __init__\n    scope=self.MAIN_SCOPE)\n  File \"../python/helper.py\", line 25, in create_network\n    return network_types[net_type](network_file=network_filename, **kwargs)\n  File \"../python/network/ACNetwork.py\", line 20, in __init__\n    scope=scope)\n  File \"../python/network/Network.py\", line 77, in __init__\n    var_sum, neur_sum, grad_sum = builder.add_summaries()\n  File \"../python/network/NetworkBuilder.py\", line 273, in add_summaries\n    grad_sum.append(tf.summary.histogram(\"grads_%d\" % i, g))\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n"
     ]
    }
   ],
   "source": [
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "sess = agent.sess\n",
    "\n",
    "# Store memories\n",
    "i = 0\n",
    "while agent.memory.size < agent.rm_start_size:\n",
    "    i += 1\n",
    "    print(i, end=\"\\r\")\n",
    "    agent.perform_learning_step(1, 1)\n",
    "\n",
    "# Learn from memories until Nan gradient created\n",
    "s1, a, s2, isterminal, q_sa, w = None, None, None, None, None, None\n",
    "while True:\n",
    "    s1, a, s2, isterminal, q_sa, w = agent.memory.get_sample(agent.batch_size)\n",
    "    s1 = agent.network._check_state(s1)\n",
    "    a = agent.network._check_actions(a)\n",
    "    _ = agent.network.learn(s1, a, q_sa)\n",
    "    feed_dict={agent.network.state: s1,\n",
    "               agent.network.actions: a, \n",
    "               agent.network.q_sa: q_sa,\n",
    "               agent.network.IS_weights: w}\n",
    "    grad_sum_ = sess.run(agent.network.grad_sum,\n",
    "                         feed_dict=feed_dict)\n",
    "    agent.network.writer.add_summary(grad_sum_) # throws error when grad is Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1:    [[ 0.52156866  0.48248366  0.40000001]]\n",
      "a:     [[0 1]]\n",
      "s2:    [[ 0.52156866  0.48248366  0.40000001]]\n",
      "isterminal:  [ 0.]\n",
      "q_sa:  [-0.20740508]\n",
      "w:     [ 1.]\n",
      "V:   [[ 23.00398064]]\n",
      "pi:  [[  0.00000000e+00   8.93349003e-24   1.00000000e+00]]\n",
      "pre_softmax:  [[-35.95811081   0.93464893  54.00688553]]\n",
      "pi_bias:  [ 0.02588907  0.10460023  0.17608647]\n",
      "pi_weights [[-0.01443296 -0.12811744 -0.01737083]\n",
      " [-0.07300077  0.06540819 -0.11601797]\n",
      " [-0.1181846   0.04768491  0.18741176]\n",
      " [-0.06038205 -0.00111259  0.19380943]\n",
      " [-0.02992778 -0.08499466  0.16891941]]\n",
      "loss_pi:  [[ nan]]  loss_v:  538.768\n",
      "d(loss_pi)/d(b_pi): global_network/pi/biases [ nan  nan  nan]\n",
      "d(loss_pi)/d(w_pi): global_network/pi/weights [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "d(loss_pi)/d(b_V): global_network/V/biases [-53.07223511]\n",
      "d(loss_V)/d(b_V): global_network/V/biases [ 46.42277145]\n"
     ]
    }
   ],
   "source": [
    "# Print values\n",
    "print(\"s1:   \", s1[:, :3, 1, 1])\n",
    "print(\"a:    \", a)\n",
    "print(\"s2:   \", s2[:, :3, 1, 1])\n",
    "print(\"isterminal: \", isterminal)\n",
    "print(\"q_sa: \", q_sa)\n",
    "print(\"w:    \", w)\n",
    "print(\"V:  \", agent.network.get_value_output(s1))\n",
    "print(\"pi: \", agent.network.get_policy_output(s1))\n",
    "\n",
    "# Get gradients\n",
    "opt = agent.network.optimizer\n",
    "var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                             scope=agent.network.scope)\n",
    "fd = {agent.network.state: s1, agent.network.actions: a, \n",
    "      agent.network.q_sa: q_sa, agent.network.IS_weights: w}\n",
    "sess = agent.network.sess\n",
    "gvs_pi = opt.compute_gradients(agent.network.loss_pi, var_list=var_list)\n",
    "grads_pi = sess.run([g for g, v in gvs_pi], feed_dict=fd)\n",
    "gvs_v = opt.compute_gradients(agent.network.loss_v, var_list=var_list)\n",
    "gvs_v = [[g, v] for g, v in gvs_v if g is not None]\n",
    "grads_v = sess.run([g for g, v in gvs_v], feed_dict=fd)\n",
    "\n",
    "# Print intermediate values and variables\n",
    "pre_softmax = tf.get_default_graph().get_tensor_by_name(\"global_network/pi/BiasAdd:0\")\n",
    "pi_bias = tf.get_default_graph().get_tensor_by_name(\"global_network/pi/biases:0\")\n",
    "pi_weights = tf.get_default_graph().get_tensor_by_name(\"global_network/pi/weights:0\")\n",
    "print(\"pre_softmax: \", sess.run(pre_softmax, feed_dict=fd))\n",
    "print(\"pi_bias: \", sess.run(pi_bias))\n",
    "print(\"pi_weights\", sess.run(pi_weights)[:5, :])\n",
    "\n",
    "# Print losses and gradients\n",
    "loss_pi, loss_v = sess.run([agent.network.loss_pi, agent.network.loss_v],\n",
    "                           feed_dict=fd)\n",
    "print(\"loss_pi: \", loss_pi, \" loss_v: \", loss_v)\n",
    "print(\"d(loss_pi)/d(b_pi): %s\" % gvs_pi[-1][1].name[:-2], grads_pi[-1])\n",
    "print(\"d(loss_pi)/d(w_pi): %s\" % gvs_pi[-2][1].name[:-2], grads_pi[-2][:5, :])\n",
    "print(\"d(loss_pi)/d(b_V): %s\" % gvs_pi[-3][1].name[:-2], grads_pi[-3])\n",
    "print(\"d(loss_V)/d(b_V): %s\" % gvs_v[-1][1].name[:-2], grads_v[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:   [[ 19.40326881]]\n",
      "pi:  [[  0.00000000e+00   1.00000000e+00   4.64825156e-08]]\n"
     ]
    }
   ],
   "source": [
    "print_values_after_nan(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that early on, the output layer diverges quickly, leading to a softmax output beyond numerical accuracy and thus 0. This, in turn, leads to $log(0)=-\\infty$ and possibly division by 0 as well, both of which backpropagate `nan` throughout the network. This [forum on stackoverflow](https://stackoverflow.com/questions/37448557/why-are-my-tensorflow-network-weights-and-costs-nan-when-i-use-relu-activations) mentioned lowering weights into the final output layer. So now we will edit the `ac_basic.json` file to initialize weights in the `pi` layer with a stddev=1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\r"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n\nCaused by op 'global_network/summaries/gradients/global_network/pi/biases/grads_0', defined at:\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-64-a3dab79cf69b>\", line 1, in <module>\n    agent = make_new_agent()\n  File \"<ipython-input-7-01f1c4964e8d>\", line 12, in make_new_agent\n    output_directory=results_dir)\n  File \"../python/helper.py\", line 17, in create_agent\n    return agent_types[agent_type](agent_file=agent_filename, **kwargs)\n  File \"../python/agent/ACERAgent.py\", line 25, in __init__\n    **kwargs)\n  File \"../python/agent/Agent.py\", line 82, in __init__\n    scope=self.MAIN_SCOPE)\n  File \"../python/helper.py\", line 25, in create_network\n    return network_types[net_type](network_file=network_filename, **kwargs)\n  File \"../python/network/ACNetwork.py\", line 20, in __init__\n    scope=scope)\n  File \"../python/network/Network.py\", line 77, in __init__\n    var_sum, neur_sum, grad_sum = builder.add_summaries()\n  File \"../python/network/NetworkBuilder.py\", line 273, in add_summaries\n    grad_sum.append(tf.summary.histogram(\"grads_%d\" % i, g))\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a3dab79cf69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                agent.network.IS_weights: w}\n\u001b[1;32m     23\u001b[0m     grad_sum_ = sess.run(agent.network.grad_sum,\n\u001b[0;32m---> 24\u001b[0;31m                          feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_sum_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# throws error when grad is Nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n\nCaused by op 'global_network/summaries/gradients/global_network/pi/biases/grads_0', defined at:\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-64-a3dab79cf69b>\", line 1, in <module>\n    agent = make_new_agent()\n  File \"<ipython-input-7-01f1c4964e8d>\", line 12, in make_new_agent\n    output_directory=results_dir)\n  File \"../python/helper.py\", line 17, in create_agent\n    return agent_types[agent_type](agent_file=agent_filename, **kwargs)\n  File \"../python/agent/ACERAgent.py\", line 25, in __init__\n    **kwargs)\n  File \"../python/agent/Agent.py\", line 82, in __init__\n    scope=self.MAIN_SCOPE)\n  File \"../python/helper.py\", line 25, in create_network\n    return network_types[net_type](network_file=network_filename, **kwargs)\n  File \"../python/network/ACNetwork.py\", line 20, in __init__\n    scope=scope)\n  File \"../python/network/Network.py\", line 77, in __init__\n    var_sum, neur_sum, grad_sum = builder.add_summaries()\n  File \"../python/network/NetworkBuilder.py\", line 273, in add_summaries\n    grad_sum.append(tf.summary.histogram(\"grads_%d\" % i, g))\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/james/anaconda3/envs/vizdoom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: global_network/summaries/gradients/global_network/pi/biases/grads_0\n\t [[Node: global_network/summaries/gradients/global_network/pi/biases/grads_0 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_network/summaries/gradients/global_network/pi/biases/grads_0/tag, global_network/summaries/gradients/gradients/global_network/pi/BiasAdd_grad/tuple/control_dependency_1/_105)]]\n"
     ]
    }
   ],
   "source": [
    "agent = make_new_agent()\n",
    "agent.initialize_new_episode()\n",
    "sess = agent.sess\n",
    "\n",
    "# Store memories\n",
    "i = 0\n",
    "while agent.memory.size < agent.rm_start_size:\n",
    "    i += 1\n",
    "    print(i, end=\"\\r\")\n",
    "    agent.perform_learning_step(1, 1)\n",
    "\n",
    "# Learn from memories until Nan gradient created\n",
    "s1, a, s2, isterminal, q_sa, w = None, None, None, None, None, None\n",
    "for i in range(10000):\n",
    "    s1, a, s2, isterminal, q_sa, w = agent.memory.get_sample(agent.batch_size)\n",
    "    s1 = agent.network._check_state(s1)\n",
    "    a = agent.network._check_actions(a)\n",
    "    _ = agent.network.learn(s1, a, q_sa)\n",
    "    feed_dict={agent.network.state: s1,\n",
    "               agent.network.actions: a, \n",
    "               agent.network.q_sa: q_sa,\n",
    "               agent.network.IS_weights: w}\n",
    "    grad_sum_ = sess.run(agent.network.grad_sum,\n",
    "                         feed_dict=feed_dict)\n",
    "    agent.network.writer.add_summary(grad_sum_) # throws error when grad is Nan\n",
    "    print(i, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   Tensor(\"global_network/loss/policy_loss:0\", shape=(?, ?), dtype=float32)\n",
      "1   Tensor(\"global_network/loss/Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = [agent.network.loss_pi, agent.network.loss_v]\n",
    "for i, l in enumerate(loss):\n",
    "    print(i, \" \", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
