{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized Experience Replay\n",
    "This will test the basic code to build an agent with prioritized experience replay (Schaul et al., 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import sys\n",
    "sys.path.insert(0, \"../python\")\n",
    "from network.Network import Network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from time import time\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build replay memory\n",
    "We will begin by initializing the basic building blocks of replay memory: arrays to store transition values, which include the state (s1), next state (s2), action taken (a), reward received (r), and whether or not the next state is terminal (isterminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set basic parameters\n",
    "capacity = 5\n",
    "state_shape = [30, 45]\n",
    "\n",
    "# Initialize arrays to store transition variables\n",
    "s1 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "s2 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "a = np.zeros(capacity, dtype=np.int32)\n",
    "r = np.zeros(capacity, dtype=np.float32)\n",
    "isterminal = np.zeros(capacity, dtype=np.float32)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that adds a transition to replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_transition(s1_, s2_, a_, r_, isterminal_, pos):\n",
    "    s1[pos] = s1_\n",
    "    s2[pos] = s2_\n",
    "    a[pos] = a_\n",
    "    r[pos] = r_\n",
    "    isterminal[pos] = isterminal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to simply adding the values into the arrays, we also must assign each transition a priority. There are two basic schemes discussed in the paper:\n",
    "- **Proportional prioritization**: $p_i = |\\delta _i| + \\epsilon$, where $\\epsilon$ is a small constant to avoid edge-cases in which the TD error is zero (and thus leads to zero probability of sampling--see below).\n",
    "- **Rank-based prioritization**: $p_i = \\frac{1}{rank(i)}$, where $rank(i)$ is the priority of transition $i$ when sorted based on $|\\delta_i|$.\n",
    "\n",
    "We will use the proportional-based scheme as its implementation is easier; in reality, both performed equally well overall, although performance varied from game to game.\n",
    "\n",
    "This function will take $\\delta_i = (r_i + Q_i'(s,a)) - Q_i(s,a)$ as input and return the priority $p_i$ of the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_priority(delta):\n",
    "    return abs(delta) + 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary heap: updating\n",
    "Sorting and selecting transitions from replay memory becomes prohibitively expensive as the replay memory size grows. If naively implemented, the time to search and insert based on priorities scales as $O(nlogn)$ and $O(n)$, respectively. To reduce this cost, we need to implement a binary heap (see [here](https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/) for a good explanation).\n",
    "\n",
    "The binary heap will be implemented using a numpy array. Since we know the number of leaves (i.e. the replay memory capacity), we can compute the total number of elements in the array. If the PER capacity is N, then the previous layer in the heap must be of size $2^{ceil(log(N))-1}$. For example if $N=20$, then the previous layer must be $2^{ceil(log(20))-1}=2^{5-1}=16$; if $N=33$, then it must be $2^{ceil(log(33))-1}=2^{6-1}=32$. The sum of all previous elements is equal to one less than twice the size of the next-to-last-layer:\n",
    "\n",
    "$\\sum_{k=0}^{ceil(log(N))-1} 2^{k}=2*2^{ceil(log(N))-1}-1=2^{ceil(log(N))}-1$\n",
    "\n",
    "Thus the total number of elements is simply the above plus the number of transitions:\n",
    "\n",
    "$2^{ceil(log(N))}-1+N$\n",
    "\n",
    "Because we will being indexing at 1 instead of 0, we will need to add one more to our array capacity:\n",
    "\n",
    "$2^{ceil(log(N))}+N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "num_leaves = 8\n",
    "num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "heap = np.zeros(num_elements, dtype=np.float32)\n",
    "print(heap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be adding in unsorted, sequential order, we will simply ad transition priorities from left to right across the bottom layer of the tree. However, while the addition is easy, we must perform additional operations to maintain the specialness of this tree. It is constructed such that the parent node is equal to the sum of the children nodes. When a priority is added, we must propagate the new value up the tree, changing the values of the parent nodes accordingly. Keeping in mind that the indices of the left and right children are given by $2i$ and $2i+1$, respectively, we can formulate the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Set starting position of transitions in heap\n",
    "start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "print(start_pos)\n",
    "\n",
    "# Recursive function to update parent of node j\n",
    "def _propagate(child_id):\n",
    "    parent_id = child_id // 2\n",
    "    heap[parent_id] = heap[2 * parent_id] + heap[2 * parent_id + 1]\n",
    "    \n",
    "# Add priority leaf to heap and update parent nodes\n",
    "def add_priority(p, i, verbose=True):  \n",
    "    # note that while heap is 1-indexed, RM is still 0-indexed\n",
    "    j = start_pos + i \n",
    "    \n",
    "    # Add priority of transition i to heap\n",
    "    heap[j] = p\n",
    "    \n",
    "    # Recursively update parent nodes\n",
    "    while j > 1:\n",
    "        if verbose: print(j, end=\" \")\n",
    "        _propagate(j)\n",
    "        j = j // 2\n",
    "    if verbose: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run through an example of propagation. We will add a few priority values to the tree and observe how they are propagated upward to maintain the special structure noted above. We will print which indices were updated and the final value of the heap after updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Initial values\n",
    "np.set_printoptions(precision=1)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4 2 \n",
      "[ 0.   3.5  3.5  0.   3.5  0.   0.   0.   3.5  0.   0.   0.   0.   0.   0.\n",
      "  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 3.5\n",
    "add_priority(3.5, 0)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 4 2 \n",
      "[ 0.   5.7  5.7  0.   5.7  0.   0.   0.   3.5  2.2  0.   0.   0.   0.   0.\n",
      "  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 2.2\n",
    "add_priority(2.2, 1)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5 2 \n",
      "[  0.   10.3  10.3   0.    5.7   4.6   0.    0.    3.5   2.2   4.6   0.\n",
      "   0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 4.6\n",
    "add_priority(4.6, 2)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working! Now let's add a list of numbers to a new heap and see if we get the result as this picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of Sum Tree](prioritized_experience_replay/sumtree.png)\n",
    "\n",
    "(credit: https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4 2 \n",
      "[ 0.  3.  3.  0.  3.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      "9 4 2 \n",
      "[  0.  13.  13.   0.  13.   0.   0.   0.   3.  10.   0.   0.   0.   0.   0.\n",
      "   0.]\n",
      "10 5 2 \n",
      "[  0.  25.  25.   0.  13.  12.   0.   0.   3.  10.  12.   0.   0.   0.   0.\n",
      "   0.]\n",
      "11 5 2 \n",
      "[  0.  29.  29.   0.  13.  16.   0.   0.   3.  10.  12.   4.   0.   0.   0.\n",
      "   0.]\n",
      "12 6 3 \n",
      "[  0.  30.  29.   1.  13.  16.   1.   0.   3.  10.  12.   4.   1.   0.   0.\n",
      "   0.]\n",
      "13 6 3 \n",
      "[  0.  32.  29.   3.  13.  16.   3.   0.   3.  10.  12.   4.   1.   2.   0.\n",
      "   0.]\n",
      "14 7 3 \n",
      "[  0.  40.  29.  11.  13.  16.   3.   8.   3.  10.  12.   4.   1.   2.   8.\n",
      "   0.]\n",
      "15 7 3 \n",
      "[  0.  42.  29.  13.  13.  16.   3.  10.   3.  10.  12.   4.   1.   2.   8.\n",
      "   2.]\n"
     ]
    }
   ],
   "source": [
    "# Create new blank heap\n",
    "num_leaves = 8\n",
    "num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "heap = np.zeros(num_elements, dtype=np.float32)\n",
    "start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "\n",
    "# List of priorities to add from example above\n",
    "priorities = [3, 10, 12, 4, 1, 2, 8, 2]\n",
    "\n",
    "for i, p in enumerate(priorities):\n",
    "    add_priority(p, i)\n",
    "    print(heap)\n",
    "\n",
    "default_heap = heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary heap: retrieval\n",
    "They match! Now that we've built the update function, we must add the other side of the coin: binary search. Like a normal binary tree search, the algorithm will be as follows:\n",
    "    \n",
    "    if value <= node.left: move left with value\n",
    "    else:                  move right with (node.left.value - value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _search(node, m, verbose):\n",
    "    # Verbose code to track search\n",
    "    if verbose:\n",
    "        print(\"Node %d, node value %d, search value %d\" % (node, heap[node], m))\n",
    "    \n",
    "    # Return value if no children\n",
    "    if 2 * node > heap.size - 1:\n",
    "        return node, heap[node]\n",
    "    \n",
    "    # Move left\n",
    "    if m <= heap[2 * node]:\n",
    "        return _search(2 * node, m, verbose)\n",
    "    \n",
    "    # Move right\n",
    "    else:\n",
    "        m = m - heap[2 * node]\n",
    "        return _search(2 * node + 1, m, verbose)\n",
    "\n",
    "def retrieve(m, verbose=True):\n",
    "    return _search(1, m, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to sample transitions based on their priority, we need to generate a random number in the range $[0, p_total]$, where $p_total=\\sum_{i} p_i$. Then we will match the random number with a transition: if the random number falls in the range of priority values in the cumulative sum function of a transition, we will choose that transition. Let's see an example of randomly generating 24 as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1, node value 42, search value 24\n",
      "Node 2, node value 29, search value 24\n",
      "Node 5, node value 16, search value 11\n",
      "Node 10, node value 12, search value 11\n",
      "Found transition 2 with priority 12\n"
     ]
    }
   ],
   "source": [
    "rand_int = 24\n",
    "i, p = retrieve(24)\n",
    "print(\"Found transition %d with priority %d\" % (i - start_pos, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's try with some more random numbers. You can verify the results by looking at the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1, node value 42, search value 12\n",
      "Node 2, node value 29, search value 12\n",
      "Node 4, node value 13, search value 12\n",
      "Node 9, node value 10, search value 9\n",
      "Found transition 1 with priority 10\n",
      "\n",
      "Node 1, node value 42, search value 29\n",
      "Node 2, node value 29, search value 29\n",
      "Node 5, node value 16, search value 16\n",
      "Node 11, node value 4, search value 4\n",
      "Found transition 3 with priority 4\n",
      "\n",
      "Node 1, node value 42, search value 35\n",
      "Node 3, node value 13, search value 6\n",
      "Node 7, node value 10, search value 3\n",
      "Node 14, node value 8, search value 3\n",
      "Found transition 6 with priority 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_int = [12, 29, 35]\n",
    "for r in rand_int:\n",
    "    i, p = retrieve(r)\n",
    "    print(\"Found transition %d with priority %d\" % (i - start_pos, p),\n",
    "          end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because of the `<=` operator in the `move left` part of the search function, ties go to the leftmost node that contains the random int in its cumulative range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary heap: performance testing\n",
    "Now let's run some tests to make sure both the update and search functions scale as $O(logN)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating heap of size 100...\n",
      "Creating heap of size 10000...\n",
      "Creating heap of size 1000000...\n",
      "Creating heap of size 100000000...\n",
      "Update times:  [8.876430988311767e-06, 1.40855073928833e-05, 1.8756589889526367e-05, 3.186120986938477e-05]\n",
      "Update time ratios:  [1.5868435648776742, 1.331623303751424]\n",
      "Search times:  [7.93600082397461e-06, 2.2762060165405274e-05, 1.8911123275756837e-05, 2.8120994567871092e-05]\n",
      "Search time ratios:  [2.868202848044223, 0.8308177352284987]\n"
     ]
    }
   ],
   "source": [
    "sizes = [10 ** (2*x) for x in range(1, 5)]\n",
    "update_time = []\n",
    "search_time = []\n",
    "for i, size in enumerate(sizes):\n",
    "    print(\"Creating heap of size %d...\" % size)\n",
    "    \n",
    "    # Create new blank heap\n",
    "    num_leaves = size\n",
    "    num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "    heap = np.zeros(num_elements, dtype=np.float32)\n",
    "    start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "    \n",
    "    # Add random priorities\n",
    "    priorities = 10 * np.random.random(num_leaves)\n",
    "    for j in range(num_leaves):\n",
    "        add_priority(priorities[j], j, verbose=False)\n",
    "    \n",
    "    # Test time to update\n",
    "    start_time = time()\n",
    "    t = 100000\n",
    "    for j in range(t):\n",
    "        #print(\"Update iteration %d of %d...\" % (j+1, t))\n",
    "        p = 10 * np.random.random()\n",
    "        k = np.random.randint(0, num_leaves)\n",
    "        add_priority(p, k, verbose=False)\n",
    "    end_time = time()\n",
    "    update_time.append((end_time - start_time) / t)\n",
    "    \n",
    "    # Test time to search\n",
    "    start_time = time()\n",
    "    t = 10000\n",
    "    for j in range(t):\n",
    "        #print(\"Search iteration %d of %d...\" % (j+1, t))\n",
    "        m = heap[1] * np.random.random()\n",
    "        retrieve(m, verbose=False)\n",
    "    end_time = time()\n",
    "    search_time.append((end_time - start_time) / t)\n",
    "\n",
    "print(\"Update times: \", update_time)\n",
    "update_time_ratios = [update_time[i+1] / update_time[i] for i in range(len(update_time)-2)]\n",
    "print(\"Update time ratios: \", update_time_ratios)\n",
    "\n",
    "print(\"Search times: \", search_time)\n",
    "search_time_ratios = [search_time[i+1] / search_time[i] for i in range(len(search_time)-2)]\n",
    "print(\"Search time ratios: \", search_time_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm not very informative... might need to check this later on desktop in case this is due to memory issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Drawing random samples with priority-based probability\n",
    "Now that we've got a working binary heap, we need to test that it samples leaf nodes in proportion to their priority values; that is, the probability $P(i)$ of sampling a transition with a priority $p_i$ is:\n",
    "\n",
    "$P(i)=\\frac{p_i}{\\sum_{k} p_k}$\n",
    "\n",
    "We will first need to encode a way to generate random numbers sampled from $[0, p_tot]$. In order to diversify the transitions sampled while still respecting priority probabilities, we will first divide the range $[0, p_tot]$ into $k$ bins, where $k$ represents the size of the minibatch. Then, from each bin, we will sample one transition uniformly. Let's generate means of creating $k$ random numbers drawn from equally spaced bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset:  [  0.   10.5  21.   31.5]\n",
      "m:       [ 10.   17.2  28.5  34. ]\n",
      "\n",
      "Offset:  [  0.   10.5  21.   31.5]\n",
      "m:       [  5.7  18.   27.8  38.5]\n",
      "\n",
      "Offset:  [  0.   10.5  21.   31.5]\n",
      "m:       [  1.5  16.9  24.7  33.1]\n",
      "\n",
      "Offset:  [  0.   10.5  21.   31.5]\n",
      "m:       [  9.   20.3  26.3  36.9]\n",
      "\n",
      "Offset:  [  0.   10.5  21.   31.5]\n",
      "m:       [  7.1  19.6  24.5  41.1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = 4\n",
    "\n",
    "for _ in range(5):\n",
    "    # Initialize matrices\n",
    "    m = np.zeros(sample_size)\n",
    "    \n",
    "    # Create offset that corresponds to start value of each bin\n",
    "    offset = np.zeros(sample_size)\n",
    "    offset[np.arange(sample_size)] = default_heap[1] * np.arange(sample_size) / sample_size\n",
    "    \n",
    "    # Draw random numbers from bin size, then add offset to create uniformly spaced distribution\n",
    "    m[np.arange(sample_size)] = (default_heap[1] / sample_size) * np.random.random(sample_size) + offset\n",
    "\n",
    "    print(\"Offset: \", offset)\n",
    "    print(\"m:      \", m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's utilize these random values to draw samples from our default heap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20069176459\n",
      "Node 1, node value 42, search value 2\n",
      "Node 2, node value 29, search value 2\n",
      "Node 4, node value 13, search value 2\n",
      "Node 8, node value 3, search value 2\n",
      "(8, 3.0)\n",
      "17.9470508164\n",
      "Node 1, node value 42, search value 17\n",
      "Node 2, node value 29, search value 17\n",
      "Node 5, node value 16, search value 4\n",
      "Node 10, node value 12, search value 4\n",
      "(10, 12.0)\n",
      "22.2054647917\n",
      "Node 1, node value 42, search value 22\n",
      "Node 2, node value 29, search value 22\n",
      "Node 5, node value 16, search value 9\n",
      "Node 10, node value 12, search value 9\n",
      "(10, 12.0)\n",
      "41.0275687936\n",
      "Node 1, node value 42, search value 41\n",
      "Node 3, node value 13, search value 12\n",
      "Node 7, node value 10, search value 9\n",
      "Node 15, node value 2, search value 1\n",
      "(15, 2.0)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_sample(sample_size, verbose=True):\n",
    "    # Initialize matrices\n",
    "    m = np.zeros(sample_size)\n",
    "    \n",
    "    # Create offset that corresponds to start value of each bin\n",
    "    offset = np.zeros(sample_size)\n",
    "    offset[np.arange(sample_size)] = default_heap[1] * np.arange(sample_size) / sample_size\n",
    "    \n",
    "    # Draw random numbers from bin size, then add offset to create uniformly spaced distribution\n",
    "    m[np.arange(sample_size)] = (default_heap[1] / sample_size) * np.random.random(sample_size) + offset\n",
    "\n",
    "    # Get sample for each random number by searching heap\n",
    "    t = []\n",
    "    for i in range(sample_size):\n",
    "        if verbose:\n",
    "            print(m[i])\n",
    "        t.append(retrieve(m[i], verbose=verbose))\n",
    "        if verbose:\n",
    "            print(t[-1])\n",
    "\n",
    "heap = default_heap\n",
    "print(get_sample(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized Experience Replay Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a PrioritizedReplayMemory class to consolidate our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PrioritizedReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity, state_shape):\n",
    "        # Initialize arrays to store transition variables\n",
    "        self.s1 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "        self.s2 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "        self.a = np.zeros(capacity, dtype=np.int32)\n",
    "        self.r = np.zeros(capacity, dtype=np.float32)\n",
    "        self.isterminal = np.zeros(capacity, dtype=np.float32) \n",
    "        \n",
    "        # Create new blank heap\n",
    "        heap_size = 2 ** math.ceil(math.log(capacity, 2)) + capacity\n",
    "        self.start_pos = 2 ** math.ceil(math.log(capacity, 2))\n",
    "        self.heap = np.zeros(heap_size, dtype=np.float32)\n",
    "\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        self.pos = 0\n",
    "    \n",
    "    def add_transition(self, s1_, s2_, a_, r_, isterminal_, p):\n",
    "        self.s1[self.pos] = s1_\n",
    "        self.s2[self.pos] = s2_\n",
    "        self.a[self.pos] = a_\n",
    "        self.r[self.pos] = r_\n",
    "        self.isterminal[self.pos] = isterminal_\n",
    "        self.add_priority(p, self.pos)\n",
    "        \n",
    "        #Increment pointer or start over if reached end\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "        self.size = min(self.size + 1, self.capacity)\n",
    "    \n",
    "    # Recursive function to update parent of node j\n",
    "    def _propagate(self, child_id):\n",
    "        parent_id = child_id // 2\n",
    "        self.heap[parent_id] = self.heap[2 * parent_id] + self.heap[2 * parent_id + 1]\n",
    "\n",
    "    # Add priority leaf to heap and update parent nodes\n",
    "    def add_priority(self, p, i):\n",
    "        # note that while heap is 1-indexed, RM is still 0-indexed\n",
    "        j = self.start_pos + i \n",
    "\n",
    "        # Add priority of transition i to heap\n",
    "        self.heap[j] = p\n",
    "\n",
    "        # Recursively update parent nodes\n",
    "        while j > 1:\n",
    "            self._propagate(j)\n",
    "            j = j // 2\n",
    "    \n",
    "    # Recursively search for node with cumulative sum range containing number\n",
    "    def _retrieve(self, node, m):\n",
    "        # Return value if no children\n",
    "        if 2 * node > self.heap.size - 1:\n",
    "            return node\n",
    "\n",
    "        # Move left\n",
    "        if m <= self.heap[2 * node]:\n",
    "            return self._retrieve(2 * node, m)\n",
    "\n",
    "        # Move right\n",
    "        else:\n",
    "            m = m - self.heap[2 * node]\n",
    "            return self._retrieve(2 * node + 1, m)\n",
    "\n",
    "    # Get random sample corresponding to random number m\n",
    "    def get_sample(self, sample_size):\n",
    "        # Initialize matrices\n",
    "        m = np.zeros(sample_size)\n",
    "\n",
    "        # Create offset that corresponds to start value of each bin\n",
    "        offset = np.zeros(sample_size)\n",
    "        offset[np.arange(sample_size)] = self.heap[1] * np.arange(sample_size) / sample_size\n",
    "        \n",
    "        # Draw random numbers from bin size, then add offset to create uniformly spaced distribution\n",
    "        m[np.arange(sample_size)] = (self.heap[1] / sample_size) * np.random.random(sample_size) + offset\n",
    "\n",
    "        t = np.zeros(sample_size, dtype=np.int32)\n",
    "        for i in range(sample_size):\n",
    "            t[i] = self._retrieve(1, m[i]) - self.start_pos\n",
    "\n",
    "        return self.s1[t], self.a[t], self.s2[t], self.r[t], self.isterminal[t], t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: DQN in ViZDoom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we would manipulate (hyper)parameters within an agent file, but currently, the agent is only set up to utilize a uniform replay memory. thus in this case, we will hard code parameters below to create a network, and then build our new prioritized ER from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Set network parameters\n",
    "phi = 1\n",
    "num_channels = 1\n",
    "output_shape = 4\n",
    "output_directory = \"../tmp/\"\n",
    "sess = tf.Session()\n",
    "train_mode = True\n",
    "lr = 0.01\n",
    "net_file = \"../networks/dqn_basic.json\"\n",
    "\n",
    "# Create main network\n",
    "main_network = Network(phi=phi, \n",
    "                       num_channels=num_channels, \n",
    "                       output_shape=output_shape,\n",
    "                       train_mode=True,\n",
    "                       learning_rate=lr,\n",
    "                       network_file=net_file,\n",
    "                       params_file=None,\n",
    "                       output_directory=output_directory,\n",
    "                       session=sess,\n",
    "                       scope=\"main_network\")\n",
    "\n",
    "# Create target network used to calculate target Q values\n",
    "target_network = Network(phi=phi, \n",
    "                         num_channels=num_channels, \n",
    "                         output_shape=output_shape,\n",
    "                         learning_rate=lr,\n",
    "                         train_mode=True,\n",
    "                         network_file=net_file,\n",
    "                         params_file=None,\n",
    "                         output_directory=output_directory,\n",
    "                         session=sess,\n",
    "                         scope=\"target_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create PER to store and sample transitions\n",
    "capacity = 100\n",
    "memory = PrioritizedReplayMemory(capacity, main_network.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DoomGame instance\n",
    "game = DoomGame()\n",
    "game.load_config(\"prioritized_experience_replay/per_test.cfg\")\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = skimage.transform.resize(img, main_network.input_shape, mode='constant')\n",
    "    img = img.astype(np.float32)\n",
    "    return img\n",
    "    \n",
    "for i in range(capacity):\n",
    "    s1 = preprocess(game.get_state().screen_buffer)\n",
    "    a = [1, 0, 0]\n",
    "    r = game.make_action(a, 4)\n",
    "    isterminal = game.is_episode_finished()\n",
    "    if isterminal:\n",
    "        s2 = None\n",
    "        game.new_episode()\n",
    "    else:\n",
    "        s2 = preprocess(game.get_state().screen_buffer)\n",
    "    p = 3 * abs(np.random.normal(loc=0, scale=10.0)) + 0.1\n",
    "    memory.add_transition(s1, s2, 0, r, isterminal, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAIMCAYAAADIN5BFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhvL/AXeRB3z/bwYrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12915ad68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get samples\n",
    "t = []\n",
    "for i in range(1000):\n",
    "    _, _, _, _, _, t_i = memory.get_sample(32)\n",
    "    t.append(t_i)\n",
    "\n",
    "t = np.asarray(t)\n",
    "\n",
    "# Count how many times each \n",
    "p_tot = memory.heap[1]\n",
    "calc_prob = np.zeros(capacity)\n",
    "actual_prob = np.zeros(capacity)\n",
    "for i in range(capacity):\n",
    "    p = memory.heap[memory.start_pos + i]\n",
    "    calc_prob[i] = p / p_tot\n",
    "    actual_prob[i] = np.sum(np.count_nonzero(t == i)) / t.size\n",
    "    #print(\"Transition %d: calculated prob=%.3f, actual prob=%.3f\" % (i, calc_prob, actual_prob))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "idx = np.arange(capacity)\n",
    "width = 0.3\n",
    "ax.bar(idx, calc_prob, width, color=\"orange\")\n",
    "ax.bar(idx + width, actual_prob, width, color=\"black\")\n",
    "fig.set_size_inches(16, 9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Debugging divide_by_zero error\n",
    "The following error occurs rarely but halts training completely:\n",
    "\n",
    "```\n",
    "/home/james/DRL/ViZDoom/myvizdoom/python/memory/PrioritizedReplayMemory.py:108: RuntimeWarning: divide by zero encountered in true_divide\n",
    "  w = (1 / self.size + 1 / P) ** self.beta\n",
    "```\n",
    "\n",
    "### Trial 1\n",
    "Placing some debugging code in the `PrioritizedReplayMemory` class led to the following output after such an occurrence:\n",
    "\n",
    "```\n",
    "t_:  [132420 134708 137428 140284 143106 143978 146100 150787 152174 155741\n",
    " 156766 159138 162823 165159 166859 169157 172953 175232 176509 178939\n",
    " 182925 184194 187485 189666 191278 195368 197115 200669 201038 205862\n",
    " 206161 106495]\n",
    "heap[t_]:  [ 0.23203613  0.24098936  0.79097128  2.3553133   1.75138795  0.38908565\n",
    "  0.24508314  0.43584165  0.38867164  0.24647366  0.26096773  0.29170811\n",
    "  2.05461168  0.16835532  0.85869598  0.36499071  0.14356624  0.32087034\n",
    "  0.59336162  0.24211463  0.20079562  0.266231    0.52754629  0.63639134\n",
    "  2.22522616  0.19536662  0.18007174  0.2150154   0.40188783  0.23568983\n",
    "  0.19346124  0.        ]\n",
    "heap[1]:  24183.8\n",
    "P:  [  9.59470435e-06   9.96492145e-06   3.27066991e-05   9.73923161e-05\n",
    "   7.24199708e-05   1.60887103e-05   1.01341993e-05   1.80220723e-05\n",
    "   1.60715899e-05   1.01916976e-05   1.07910282e-05   1.20621444e-05\n",
    "   8.49582866e-05   6.96150028e-06   3.55071206e-05   1.50923834e-05\n",
    "   5.93647064e-06   1.32680034e-05   2.45355313e-05   1.00114512e-05\n",
    "   8.30290810e-06   1.10086639e-05   2.18140631e-05   2.63148122e-05\n",
    "   9.20132079e-05   8.07841934e-06   7.44597492e-06   8.89089642e-06\n",
    "   1.66180798e-05   9.74578597e-06   7.99963163e-06   0.00000000e+00]\n",
    "size:  80000\n",
    "beta:  0.48100000000000004\n",
    "w:  [ 259.2046814   254.52714539  143.70098877   85.01971436   98.04109192\n",
    "  202.1451416   252.47322083  191.40705872  202.24868774  251.78707886\n",
    "  244.96092224  232.18536377   90.79293823  302.45443726  138.13327026\n",
    "  208.45748901  326.53738403  221.78416443  165.0092926   253.95744324\n",
    "  277.8755188   242.61949158  174.60945129  159.54518127   87.37518311\n",
    "  281.56329346  292.82339478  268.87921143  199.02180481  257.2640686\n",
    "  282.89376831           inf]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual size of the numpy array `heap` is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211072\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "capacity = 80000\n",
    "heap_size = 2 ** math.ceil(math.log(capacity, 2)) + capacity\n",
    "print(heap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 80000 positions of the heap represent leaves, or priorities tied to stored transitions. The rest are intermediate nodes that should not be sampled directly. The leaves begin at position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131072\n"
     ]
    }
   ],
   "source": [
    "start_pos = 2 ** math.ceil(math.log(capacity, 2))\n",
    "print(start_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the sample 106495 should not have been taken. This index probably represents the rightmost branches of the binary tree that have no leaf nodes and thus no values (since parents equal sum of children in this special heap). Here is the code for obtaining samples from PER (along with debugging print statements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample(self, sample_size):\n",
    "        # Initialize matrices\n",
    "        m = np.zeros(sample_size)\n",
    "\n",
    "        # Create offset that corresponds to start value of each bin\n",
    "        offset = np.zeros(sample_size)\n",
    "        offset[np.arange(sample_size)] = ( self.heap[1] \n",
    "                                           * np.arange(sample_size) / sample_size )\n",
    "        \n",
    "        # Draw random numbers from bin size, \n",
    "        # then add offset to create uniformly spaced distribution\n",
    "        m[np.arange(sample_size)] = ( (self.heap[1] / sample_size)\n",
    "                                       * np.random.random(sample_size) + offset )\n",
    "\n",
    "        # Retrieve transition indices with probability proportional\n",
    "        # to priority values\n",
    "        t = np.zeros(sample_size, dtype=np.int32)\n",
    "        for i in range(sample_size):\n",
    "            t[i] = self._retrieve(1, m[i]) - self.start_pos\n",
    "        \n",
    "        # Calculate importance-sampling (IS) weights w_i of transition:\n",
    "        # w_i = (1/N * 1/P_i) ** β\n",
    "        # where P_i = probability of transition i, N = memory size, \n",
    "        # and β = hyperparameter\n",
    "        t_ = self.start_pos + t\n",
    "        P = self.heap[t_] / self.heap[1]\n",
    "        w = (1 / self.size + 1 / P) ** self.beta\n",
    "        w = w / np.max(w) # normalize weights so all <= 1.0\n",
    "        if (P == 0).any() or self.size == 0:\n",
    "            print(\"t_: \", t_)\n",
    "            print(\"heap[t_]: \", self.heap[t_])\n",
    "            print(\"heap[1]: \", self.heap[1])\n",
    "            print(\"P: \", P)\n",
    "            print(\"size: \", self.size)\n",
    "            print(\"beta: \", self.beta)\n",
    "            print(\"w: \", w)\n",
    "            #np.savetxt(\"../tmp/tmp_results/heap.txt\", self.heap)\n",
    "        \n",
    "        # Stack overlapping frames from s1 to stored frames of s2 to\n",
    "        # recreate full s2 state\n",
    "        if self.overlap > 0:    \n",
    "            s2 = np.concatenate((self.s1[[t] + [slice(None)] * self.chdim \n",
    "                                 + [slice(None, self.overlap)]], \n",
    "                                 self.s2[t]), \n",
    "                                 axis=self.chdim+1)\n",
    "        else:\n",
    "            s2 = self.s2[t]\n",
    "\n",
    "        return self.s1[t], self.a[t], s2, self.isterminal[t], self.r[t], w, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the first section of code to make sure there are no obvious errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:  [   495.22668181   1057.47822678   1936.00505265   2955.88952402\n",
      "   3615.79895958   4492.79984344   4986.08394442   5492.47753336\n",
      "   6696.38173415   7382.0807392    8092.75284115   8828.18859286\n",
      "   9460.07466548  10369.55243044  10813.91309189  11363.46859654\n",
      "  12129.16979983  13256.78818569  13873.01283026  14632.18655498\n",
      "  15768.88803377  16457.99541593  16663.10143242  17930.8221608\n",
      "  18819.54953062  19485.24513183  20082.04107018  20691.62395053\n",
      "  21768.2299554   22124.02567792  23313.02903128  23868.57877195]\n",
      "offset:  [     0.         755.74375   1511.4875    2267.23125   3022.975\n",
      "   3778.71875   4534.4625    5290.20625   6045.95      6801.69375\n",
      "   7557.4375    8313.18125   9068.925     9824.66875  10580.4125\n",
      "  11336.15625  12091.9      12847.64375  13603.3875   14359.13125\n",
      "  15114.875    15870.61875  16626.3625   17382.10625  18137.85     18893.59375\n",
      "  19649.3375   20405.08125  21160.825    21916.56875  22672.3125\n",
      "  23428.05625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_size = 32\n",
    "heap_1 = 24183.8\n",
    "\n",
    "# Initialize matrices\n",
    "m = np.zeros(sample_size)\n",
    "\n",
    "# Create offset that corresponds to start value of each bin\n",
    "offset = np.zeros(sample_size)\n",
    "offset[np.arange(sample_size)] = ( heap_1\n",
    "                                   * np.arange(sample_size) / sample_size )\n",
    "\n",
    "# Draw random numbers from bin size, \n",
    "# then add offset to create uniformly spaced distribution\n",
    "m[np.arange(sample_size)] = ( (heap_1 / sample_size)\n",
    "                               * np.random.random(sample_size) + offset )\n",
    "\n",
    "print(\"m: \", m)\n",
    "print(\"offset: \", offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good. Here is the traceback from the node that caused the zero division error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106495\n",
      "53247  moved right\n",
      "26623  moved right\n",
      "13311  moved right\n",
      "6655  moved right\n",
      "3327  moved right\n",
      "1663  moved right\n",
      "831  moved right\n",
      "415  moved right\n",
      "207  moved right\n",
      "103  moved right\n",
      "51  moved right\n",
      "25  moved right\n",
      "12  moved right\n",
      "6  moved left\n",
      "3  moved left\n",
      "1  moved left\n"
     ]
    }
   ],
   "source": [
    "node = 106495\n",
    "print(node)\n",
    "while node > 1:\n",
    "    p = node\n",
    "    c = node // 2\n",
    "    if p % c == 0:\n",
    "        print(c, \" moved left\")\n",
    "    else:\n",
    "        print(c, \" moved right\")\n",
    "    node = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rightmost leaf has the following traceback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211072\n",
      "105536  moved left\n",
      "52768  moved left\n",
      "26384  moved left\n",
      "13192  moved left\n",
      "6596  moved left\n",
      "3298  moved left\n",
      "1649  moved left\n",
      "824  moved right\n",
      "412  moved left\n",
      "206  moved left\n",
      "103  moved left\n",
      "51  moved right\n",
      "25  moved right\n",
      "12  moved right\n",
      "6  moved left\n",
      "3  moved left\n",
      "1  moved left\n"
     ]
    }
   ],
   "source": [
    "node = 211072\n",
    "print(node)\n",
    "while node > 1:\n",
    "    p = node\n",
    "    c = node // 2\n",
    "    if p % c == 0:\n",
    "        print(c, \" moved left\")\n",
    "    else:\n",
    "        print(c, \" moved right\")\n",
    "    node = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus at node 103, the retrieve function should have moved left but instead moved right, putting it on a branch that had no terminal leaf nodes. After that decision, it only moved right the rest of the way likely because all nodes it was encountering were 0. Unfortunately, it is difficult to see why this happened at node 103 unless we have access to the full `heap` array, which I will save during the next debugging run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trial 2\n",
    "This time, I saved the heap values to `heap.csv` and got the following debugging print out after ~ 500,000 learning steps:\n",
    "```\n",
    "m: [   1839.63825045    4295.68753363    7978.25184885   11267.53480135\n",
    "   16367.02605193   21243.5353934    24372.04660502   26462.43133402\n",
    "   31852.52263506   32418.79534471   36479.43148083   41979.9850571\n",
    "   45860.06704717   49625.81022126   53302.31829694   54461.63846034\n",
    "   58726.49416338   62097.08856989   67398.40005856   69241.81091996\n",
    "   74107.12231262   77081.00921093   82183.06112002   84418.09530725\n",
    "   86759.02481597   92552.67349783   93611.22490686   98538.00485737\n",
    "  103135.73647588  107257.0802528   108322.32956015  115090.9649345 ]\n",
    "  \n",
    "t_:  [132344 134148 136777 139079 142612 145905 147951 149220 152427 152701\n",
    " 153669 156962 159839 162542 165305 166245 169427 172084 175929 177390\n",
    " 180999 183137 186888 188608 190304 194642 195397 198906 202371 205315\n",
    " 206142 131071]\n",
    " \n",
    "heap[t_]:  [  3.57136917   0.59005439   3.57996511   2.5988493    2.42636847\n",
    "   3.53408241   1.85923672   4.25455856   4.0738759    3.1902113\n",
    "  37.12011719   5.91703987   1.92212605   0.58849883   0.60191655\n",
    "   1.94672382   2.38106942   2.90546632   1.20598602   2.63270354\n",
    "   3.64027071   5.93819237   4.39834642   1.10890043   1.08353031\n",
    "   1.53687251   3.5494628    1.83276606   0.49460229   4.64636326\n",
    "   1.90546358   0.        ]\n",
    "   \n",
    "heap[1]:  115091.0\n",
    "\n",
    "P:  [  3.10308387e-05   5.12685210e-06   3.11055264e-05   2.25808271e-05\n",
    "   2.10821800e-05   3.07068622e-05   1.61544976e-05   3.69669178e-05\n",
    "   3.53970063e-05   2.77190411e-05   3.22528504e-04   5.14118510e-05\n",
    "   1.67009293e-05   5.11333610e-06   5.22992013e-06   1.69146533e-05\n",
    "   2.06885870e-05   2.52449554e-05   1.04785458e-05   2.28749795e-05\n",
    "   3.16295082e-05   5.15956417e-05   3.82162616e-05   9.63499042e-06\n",
    "   9.41455528e-06   1.33535459e-05   3.08404997e-05   1.59244992e-05\n",
    "   4.29749025e-06   4.03712256e-05   1.65561523e-05   0.00000000e+00]\n",
    "   \n",
    "size:  80000\n",
    "\n",
    "beta:  0.7\n",
    "```\n",
    "Remember that `m` represents the cumulative sum value to search for, and `t_` represents the heap index corresponding to the cumulative sum `m`. Let's define the functions for PER and load the saved heap, walking through the recursive search step-by-step. The error occurred for the last index, with `m=115090.9649345` and `t_=131071`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve(node, m):\n",
    "    print(\"Node:\", node, \"; m:\", m, end = \" ; \")\n",
    "    # Return value if no children (i.e. leaf)\n",
    "    if 2 * node > heap.size - 1:\n",
    "        return node\n",
    "    \n",
    "    print(\"Left child:\", heap[2*node], end=\" ; \")\n",
    "    # Move left\n",
    "    if m <= heap[2 * node]:\n",
    "        print(\"Move left\")\n",
    "        return retrieve(2 * node, m)\n",
    "\n",
    "    # Move right\n",
    "    else:\n",
    "        print(\"Move right\")\n",
    "        m = m - heap[2 * node]\n",
    "        return retrieve(2 * node + 1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heap = np.loadtxt('./prioritized_experience_replay/heap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this replicates what was seen in the printout above. Let's now walk through it step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 1 ; m: 115090.9649345 ; Left child: 95317.59375 ; Move right\n",
      "Node: 3 ; m: 19773.3711845 ; Left child: 19773.3710938 ; Move right\n",
      "Node: 7 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 15 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 31 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 63 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 127 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 255 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 511 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 1023 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 2047 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 4095 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 8191 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 16383 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 32767 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 65535 ; m: 9.07500070753e-05 ; Left child: 0.0 ; Move right\n",
      "Node: 131071 ; m: 9.07500070753e-05 ; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "131071"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve(1, 115090.9649345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the traceback from the rightmost node above (trial 1), the search cannot move to the right at Node 3; otherwise, it continues on a nonsense path that contains unused nodes. The total cumulative sum is given by `heap[1]` (1-indexed), which serves as the basis for generating random samples from uniformly distributed bins (i.e. generating `m`). The value of `m` is less than `heap[1]=115091.0`, which is good, but let's check the children nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heap[2]: 95317.59375 ; heap[3] 19773.3710938\n",
      "heap[2] + heap[3] = 115090.964844\n",
      "heap[1]: 115090.96875\n",
      "calculated total: 115090.964338\n"
     ]
    }
   ],
   "source": [
    "print(\"heap[2]:\", heap[2], \"; heap[3]\", heap[3])\n",
    "print(\"heap[2] + heap[3] =\", heap[2] + heap[3])\n",
    "print(\"heap[1]:\", heap[1])\n",
    "print(\"calculated total:\", np.sum(heap[131072:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the issue lies in the propagation function that updates parent nodes: over many iterations, slight numerical errors in propagation up the tree accumulate to cause `heap[1]` to slightly differ from the actual total of all leaves in the tree. In this case, the difference is only a few-thousandths, but the value of `m` snuck into this small interval:\n",
    "\n",
    "```\n",
    "calculated total < heap[2] + heap[3] < m              < heap[1]\n",
    "115090.964338      115090.964844       115090.9649345   115090.96875\n",
    "```\n",
    "\n",
    "The same thing probably occurred in trial 1 further down the tree, where the `m` value snuck into a similar inaccuracy interval between the parent and children nodes.\n",
    "\n",
    "To fix this, it would probably be best to pad `m` on the border cases, but the value will depend on the size and values of the replay memory. If too small, it might not cover the inaccuracy gap and allow the same error, but if too large, it might prohibit the first and last bin(s) from being accessible. For now, since the error occurs so rarely (every ~ 100,000 steps), I will cover errors with a `try-except` clause and increase the `heap` data type to `np.float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
