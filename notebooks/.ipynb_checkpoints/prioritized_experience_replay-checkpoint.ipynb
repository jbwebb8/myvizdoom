{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized Experience Replay\n",
    "This will test the basic code to build an agent with prioritized experience replay (Schaul et al., 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import sys\n",
    "sys.path.insert(0, \"../python\")\n",
    "from Network import Network\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we would manipulate (hyper)parameters within an agent file, but currently, the agent is only set up to utilize a uniform replay memory. thus in this case, we will hard code parameters below to create a network, and then build our new prioritized ER from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Set network parameters\n",
    "phi = 1\n",
    "num_channels = 1\n",
    "output_shape = 4\n",
    "output_directory = \"../tmp/\"\n",
    "sess = tf.Session()\n",
    "train_mode = True\n",
    "lr = 0.01\n",
    "net_file = \"../networks/dqn_basic.json\"\n",
    "\n",
    "# Create main network\n",
    "main_network = Network(phi=phi, \n",
    "                       num_channels=num_channels, \n",
    "                       output_shape=output_shape,\n",
    "                       train_mode=True,\n",
    "                       learning_rate=lr,\n",
    "                       network_file=net_file,\n",
    "                       params_file=None,\n",
    "                       output_directory=output_directory,\n",
    "                       session=sess,\n",
    "                       scope=\"main_network\")\n",
    "\n",
    "# Create target network used to calculate target Q values\n",
    "target_network = Network(phi=phi, \n",
    "                         num_channels=num_channels, \n",
    "                         output_shape=output_shape,\n",
    "                         learning_rate=lr,\n",
    "                         train_mode=True,\n",
    "                         network_file=net_file,\n",
    "                         params_file=None,\n",
    "                         output_directory=output_directory,\n",
    "                         session=sess,\n",
    "                         scope=\"target_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build prioritized experience replay memory\n",
    "Now that the initial network is created, we will build a replay memory that incorporates prioritization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by initializing the basic building blocks of replay memory: arrays to store transition values, which include the state (s1), next state (s2), action taken (a), reward received (r), and whether or not the next state is terminal (isterminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic parameters\n",
    "capacity = 5\n",
    "state_shape = [30, 45]\n",
    "\n",
    "# Initialize arrays to store transition variables\n",
    "s1 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "s2 = np.zeros([capacity] + list(state_shape), dtype=np.float32)\n",
    "a = np.zeros(capacity, dtype=np.int32)\n",
    "r = np.zeros(capacity, dtype=np.float32)\n",
    "isterminal = np.zeros(capacity, dtype=np.float32)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that adds a transition to replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_transition(s1_, s2_, a_, r_, isterminal_, pos):\n",
    "    s1[pos] = s1_\n",
    "    s2[pos] = s2_\n",
    "    a[pos] = a_\n",
    "    r[pos] = r_\n",
    "    isterminal[pos] = isterminal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to simply adding the values into the arrays, we also must assign each transition a priority. There are two basic schemes discussed in the paper:\n",
    "- **Proportional prioritization**: $p_i = |\\delta _i| + \\epsilon$, where $\\epsilon$ is a small constant to avoid edge-cases in which the TD error is zero (and thus leads to zero probability of sampling--see below).\n",
    "- **Rank-based prioritization**: $p_i = \\frac{1}{rank(i)}$, where $rank(i)$ is the priority of transition $i$ when sorted based on $|\\delta_i|$.\n",
    "\n",
    "We will use the proportional-based scheme as its implementation is easier; in reality, both performed equally well overall, although performance varied from game to game.\n",
    "\n",
    "This function will take $\\delta_i = (r_i + Q_i'(s,a)) - Q_i(s,a)$ as input and return the priority $p_i$ of the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_priority(delta):\n",
    "    return abs(delta) + 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting and selecting transitions from replay memory becomes prohibitively expensive as the replay memory size grows. If naively implemented, the time to search and insert based on priorities scales as $O(nlogn)$ and $O(n)$, respectively. To reduce this cost, we need to implement a binary heap (see [here](https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/) for a good explanation).\n",
    "\n",
    "The binary heap will be implemented using a numpy array. Since we know the number of leaves (i.e. the replay memory capacity), we can compute the total number of elements in the array. If the PER capacity is N, then the previous layer in the heap must be of size $2^{ceil(log(N))-1}$. For example if $N=20$, then the previous layer must be $2^{ceil(log(20))-1}=2^{5-1}=16$; if $N=33$, then it must be $2^{ceil(log(33))-1}=2^{6-1}=32$. The sum of all previous elements is equal to one less than twice the size of the next-to-last-layer:\n",
    "\n",
    "$\\sum_{k=0}^{ceil(log(N))-1} 2^{k}=2*2^{ceil(log(N))-1}-1=2^{ceil(log(N))}-1$\n",
    "\n",
    "Thus the total number of elements is simply the above plus the number of transitions:\n",
    "\n",
    "$2^{ceil(log(N))}-1+N$\n",
    "\n",
    "Because we will being indexing at 1 instead of 0, we will need to add one more to our array capacity:\n",
    "\n",
    "$2^{ceil(log(N))}+N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "num_leaves = 8\n",
    "num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "heap = np.zeros(num_elements, dtype=np.float32)\n",
    "print(heap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be adding in unsorted, sequential order, we will simply ad transition priorities from left to right across the bottom layer of the tree. However, while the addition is easy, we must perform additional operations to maintain the specialness of this tree. It is constructed such that the parent node is equal to the sum of the children nodes. When a priority is added, we must propagate the new value up the tree, changing the values of the parent nodes accordingly. Keeping in mind that the indices of the left and right children are given by $2i$ and $2i+1$, respectively, we can formulate the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Set starting position of transitions in heap\n",
    "start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "print(start_pos)\n",
    "\n",
    "# Recursive function to update parent of node j\n",
    "def _propagate(child_id):\n",
    "    parent_id = child_id // 2\n",
    "    heap[parent_id] = heap[2 * parent_id] + heap[2 * parent_id + 1]\n",
    "    \n",
    "# Add priority leaf to heap and update parent nodes\n",
    "def add_priority(p, i, verbose=True):  \n",
    "    # note that while heap is 1-indexed, RM is still 0-indexed\n",
    "    j = start_pos + i \n",
    "    \n",
    "    # Add priority of transition i to heap\n",
    "    heap[j] = p\n",
    "    \n",
    "    # Recursively update parent nodes\n",
    "    while j > 1:\n",
    "        if verbose: print(j, end=\" \")\n",
    "        _propagate(j)\n",
    "        j = j // 2\n",
    "    if verbose: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run through an example of propagation. We will add a few priority values to the tree and observe how they are propagated upward to maintain the special structure noted above. We will print which indices were updated and the final value of the heap after updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Initial values\n",
    "np.set_printoptions(precision=1)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4 2 \n",
      "[ 0.   3.5  3.5  0.   3.5  0.   0.   0.   3.5  0.   0.   0.   0.   0.   0.\n",
      "  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 3.5\n",
    "add_priority(3.5, 0)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 4 2 \n",
      "[ 0.   5.7  5.7  0.   5.7  0.   0.   0.   3.5  2.2  0.   0.   0.   0.   0.\n",
      "  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 2.2\n",
    "add_priority(2.2, 1)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5 2 \n",
      "[  0.   10.3  10.3   0.    5.7   4.6   0.    0.    3.5   2.2   4.6   0.\n",
      "   0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "# Add priority 4.6\n",
    "add_priority(4.6, 2)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working! Now let's add a list of numbers to a new heap and see if we get the result as this picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of Sum Tree](prioritized_experience_replay/sumtree.png)\n",
    "\n",
    "(credit: https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4 2 \n",
      "[ 0.  3.  3.  0.  3.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      "9 4 2 \n",
      "[  0.  13.  13.   0.  13.   0.   0.   0.   3.  10.   0.   0.   0.   0.   0.\n",
      "   0.]\n",
      "10 5 2 \n",
      "[  0.  25.  25.   0.  13.  12.   0.   0.   3.  10.  12.   0.   0.   0.   0.\n",
      "   0.]\n",
      "11 5 2 \n",
      "[  0.  29.  29.   0.  13.  16.   0.   0.   3.  10.  12.   4.   0.   0.   0.\n",
      "   0.]\n",
      "12 6 3 \n",
      "[  0.  30.  29.   1.  13.  16.   1.   0.   3.  10.  12.   4.   1.   0.   0.\n",
      "   0.]\n",
      "13 6 3 \n",
      "[  0.  32.  29.   3.  13.  16.   3.   0.   3.  10.  12.   4.   1.   2.   0.\n",
      "   0.]\n",
      "14 7 3 \n",
      "[  0.  40.  29.  11.  13.  16.   3.   8.   3.  10.  12.   4.   1.   2.   8.\n",
      "   0.]\n",
      "15 7 3 \n",
      "[  0.  42.  29.  13.  13.  16.   3.  10.   3.  10.  12.   4.   1.   2.   8.\n",
      "   2.]\n"
     ]
    }
   ],
   "source": [
    "# Create new blank heap\n",
    "num_leaves = 8\n",
    "num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "heap = np.zeros(num_elements, dtype=np.float32)\n",
    "start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "\n",
    "# List of priorities to add from example above\n",
    "priorities = [3, 10, 12, 4, 1, 2, 8, 2]\n",
    "\n",
    "for i, p in enumerate(priorities):\n",
    "    add_priority(p, i)\n",
    "    print(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They match! Now that we've built the update function, we must add the other side of the coin: binary search. Like a normal binary tree search, the algorith will be as follows:\n",
    "    \n",
    "    if value <= node.left: move left with value\n",
    "    else:                  move right with (node.left.value - value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _search(node, m, verbose):\n",
    "    # Verbose code to track search\n",
    "    if verbose:\n",
    "        print(\"Node %d, node value %d, search value %d\" % (node, heap[node], m))\n",
    "    \n",
    "    # Return value if no children\n",
    "    if 2 * node > heap.size - 1:\n",
    "        return node, heap[node]\n",
    "    \n",
    "    # Move left\n",
    "    if m <= heap[2 * node]:\n",
    "        return _search(2 * node, m, verbose)\n",
    "    \n",
    "    # Move right\n",
    "    else:\n",
    "        m = m - heap[2 * node]\n",
    "        return _search(2 * node + 1, m, verbose)\n",
    "\n",
    "def retrieve(m, verbose=True):\n",
    "    return _search(1, m, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to sample transitions based on their priority, we need to generate a random number in the range $[0, p_total]$, where $p_total=\\sum_{i} p_i$. Then we will match the random number with a transition: if the random number falls in the range of priority values in the cumulative sum function of a transition, we will choose that transition. Let's see an example of randomly generating 24 as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1, node value 42, search value 24\n",
      "Node 2, node value 29, search value 24\n",
      "Node 5, node value 16, search value 11\n",
      "Node 10, node value 12, search value 11\n",
      "Found transition 2 with priority 12\n"
     ]
    }
   ],
   "source": [
    "rand_int = 24\n",
    "i, p = retrieve(24)\n",
    "print(\"Found transition %d with priority %d\" % (i - start_pos, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's try with some more random numbers. You can verify the results by looking at the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1, node value 42, search value 12\n",
      "Node 2, node value 29, search value 12\n",
      "Node 4, node value 13, search value 12\n",
      "Node 9, node value 10, search value 9\n",
      "Found transition 1 with priority 10\n",
      "\n",
      "Node 1, node value 42, search value 29\n",
      "Node 2, node value 29, search value 29\n",
      "Node 5, node value 16, search value 16\n",
      "Node 11, node value 4, search value 4\n",
      "Found transition 3 with priority 4\n",
      "\n",
      "Node 1, node value 42, search value 35\n",
      "Node 3, node value 13, search value 6\n",
      "Node 7, node value 10, search value 3\n",
      "Node 14, node value 8, search value 3\n",
      "Found transition 6 with priority 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_int = [12, 29, 35]\n",
    "for r in rand_int:\n",
    "    i, p = retrieve(r)\n",
    "    print(\"Found transition %d with priority %d\" % (i - start_pos, p),\n",
    "          end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because of the `<=` operator in the `move left` part of the search function, ties go to the leftmost node that contains the random int in its cumulative range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run some tests to make sure both the update and search functions scale as $O(logN)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating heap of size 1024...\n",
      "Creating heap of size 4096...\n",
      "Creating heap of size 16384...\n",
      "Creating heap of size 65536...\n",
      "Creating heap of size 262144...\n",
      "Update times:  [1.2619733810424804e-05, 1.143193244934082e-05, 1.329207420349121e-05, 1.4959096908569336e-05, 1.6237974166870117e-05]\n",
      "Update time ratios:  [0.9058774631123538, 1.1627145508769734, 1.125414790766085]\n",
      "Search times:  [1.3097047805786133e-05, 1.2251138687133789e-05, 1.611495018005371e-05, 1.6282081604003907e-05, 1.766824722290039e-05]\n",
      "Search time ratios:  [0.9354122294431398, 1.3153838668872238, 1.0103712032667072]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "sizes = [4 ** x for x in range(5, 10)]\n",
    "update_time = []\n",
    "search_time = []\n",
    "for i, size in enumerate(sizes):\n",
    "    print(\"Creating heap of size %d...\" % size)\n",
    "    \n",
    "    # Create new blank heap\n",
    "    num_leaves = size\n",
    "    num_elements = 2 ** math.ceil(math.log(num_leaves, 2)) + num_leaves\n",
    "    heap = np.zeros(num_elements, dtype=np.float32)\n",
    "    start_pos = 2 ** math.ceil(math.log(num_leaves, 2))\n",
    "    \n",
    "    # Add random priorities\n",
    "    priorities = 10 * np.random.random(num_leaves)\n",
    "    for j in range(num_leaves):\n",
    "        add_priority(priorities[j], j, verbose=False)\n",
    "    \n",
    "    # Test time to update\n",
    "    start_time = time()\n",
    "    t = 1000\n",
    "    for j in range(t):\n",
    "        #print(\"Update iteration %d of %d...\" % (j+1, t))\n",
    "        p = 10 * np.random.random()\n",
    "        k = np.random.randint(0, num_leaves)\n",
    "        add_priority(p, k, verbose=False)\n",
    "    end_time = time()\n",
    "    update_time.append((end_time - start_time) / t)\n",
    "    \n",
    "    # Test time to search\n",
    "    start_time = time()\n",
    "    t = 1000\n",
    "    for j in range(t):\n",
    "        #print(\"Search iteration %d of %d...\" % (j+1, t))\n",
    "        m = heap[1] * np.random.random()\n",
    "        retrieve(m, verbose=False)\n",
    "    end_time = time()\n",
    "    search_time.append((end_time - start_time) / t)\n",
    "\n",
    "print(\"Update times: \", update_time)\n",
    "update_time_ratios = [update_time[i+1] / update_time[i] for i in range(len(update_time)-2)]\n",
    "print(\"Update time ratios: \", update_time_ratios)\n",
    "\n",
    "print(\"Search times: \", search_time)\n",
    "search_time_ratios = [search_time[i+1] / search_time[i] for i in range(len(search_time)-2)]\n",
    "print(\"Search time ratios: \", search_time_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vizdoom)",
   "language": "python",
   "name": "vizdoom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
